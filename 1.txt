****
# Введение <a name="1"></a>

Воплощение потенциала идей, заложенных в концепцию Интернета вещей, способно существенно изменить уклад современной экономики. Благодаря внедрению масштабируемых облачных решений, использованию большого количества датчиков и распределенных микропроцессорных систем уже в ближайшее время могут быть созданы прорывные решения в таких областях, как: транспорт, сельское хозяйство, промышленное производство, здравоохранение, социальная сфера, быт и других. Все большее количество компаний обращает внимание на применение идей и технологий Интернета вещей для внедрения аналитики их деятельности и поиска новых возможностей для продуктов и услуг.

> *Интернет вещей (англ. Internet of Things, IoT) — это концепция вычислительной сети физических объектов («вещей»), оснащённых встроенными технологиями для взаимодействия друг с другом или с внешней средой.*
> 

Перечислим некоторые интересные факты:
-   По оценкам специалистов, к 2020 году к сети Интернет будет подключено до 50 млрд устройств, 20 млрд из них будут задействованы в инфраструктуре IoT.

![Прогноз количества устройств, подключенных к сети Интернет](assets/intro01.jpg)

-   До 90% данных, анализируемых устройствами Интернета вещей ранее не подвергались обработке.
-   До 60% данных, получаемых устройствами Интернета вещей, остаются актуальными лишь несколько миллисекунд.
-   В настоящее время только 0,1% устройств, способных выполнять полезную вычислительную нагрузку, подключены к сети.

По данным аналитических агенств растет количество проектов применения технологий IoT в медицине. Аналитики обнаружили, что 17% из передовых медицинских проектов используют концепцию IoT, а почти 30% проектов работают над интеграцией технологий в медицинскую практику. Статистика ясно показывает: медицинские компании заинтересованы в работе с новыми технологиями и готовы сотрудничать с разработчиками новых решений.

Однако, существенной проблемой при реализации проектов IoT в медицине является уязвимость данных. Серверы, используемые для подключения устройств IoT и обмена критическими медицинскими данными, должны обладать высокой надежностью. Одним из решений, повышающих надежность хранения информации является технология блокчейн, которая способна защитить процесс хранения посредством децентрализации и шифрования. 
Применение технологии блокчейн позволит получать и анализировать информацию о здоровье пациента, передаваемую устройствами, находящимися в контакте с пациентом. При этом становится возможным получать оперативную информацию и использовать ее для различных целей. Возможными преимуществами такого оперативного контроля за состоянием пациентов могут являтся: оперативное реагирование, оптимизация расходов, повышеие качества медицинских услуг.

****
## Инфраструктура типового решения IoT <a name="11"></a>

> 
>Под типовым решением Интернета вещей в данном конкурсе понимается распределенная кибер-физическая система, интегрирующая вычислительные ресурсы в физические процессы. В такой системе должны быть реализованы следующие основные функции:
> 

-   Сбор первичных данных с помощью сенсоров, расположенных в непосредственной близости от реальных объектов.
-   Управление объектами через актуаторы, подключенные к микрокомпьютерам.
-   Передача первичных данных от микрокомпьютеров в вычислительный хаб и в обратном направлении.
-   Первичная обработка данных в вычислительном хабе, формирование пакетов данных для передачи их в облако.
-   Получение и хранение данных в облаке.
-   Аналитическая обработка в облаке и формирование ключевых показателей эффективности (KPI) на основе данных об объектах, данных от сторонних источников, исторических данных.
-   Визуализация данных и результатов анализа на различных платформах: мобильных устройствах, носимой электронике, планшетах, компьютерах, мониторах и пр.
-   Прием команд от внешних управляющих консолей.
-   Принятие решений на основе KPI и команд, выработка управляющих и информационных сообщений для актуаторов.
-   Передача управляющих сообщений в вычислительные хабы.

Примером подобной системы является структура, представленная на следующем рисунке.

![Пример решения Интернета вещей](assets/intro03.png)
**Пример решения Интернета вещей**

> 
> Мы используем в качестве примера распределенную систему мониторинга состояния пациентов на основе системы смарт-контрактов.***
> 
> Смарт-контракт (англ. Smart contract — умный контракт) — компьютерный алгоритм, предназначенный для заключения и поддержания коммерческих контрактов в технологии блокчейн.
> 

Системы смарт-контрактов позволяют сохранить информацию о произошедших событиях в надежном и распределенном хранилище, построенной по технологии цепочки блоков (blockchain). Это обеспечивает следующие преимущества подобных систем, которые могут быть применены в области медицины:

- Надежное хранение последовательности событий и невозможность искажения ранее записанной информации.
- Открытый доступ к информации о событиях и, как следствие, открытая аналитика на основе данных системы blockchain.
- Использование данных для взаимодействия потребителей и  поставщиков (пациентов и клиник, покупателей и производителей лекарств, страховых компаний и клиник и т.п.)

Стоит сразу отметить, что данные о здоровье человека являются персональными данными, в связи с чем ее использование должно быть деперсонализированы. Поэтому вся информация персонального характера должна храниться в закрытых хранилищах. Мы используем приватную облачную платформу для реализации функций хранения.


****
## Проект хакатона <a name="11"></a>

Всем командам предлагается собрать template-проект, который может быть модифицирован командами для реализации собственных идей.  
В проекте использовано следующее оборудование:

-   Смартфон под управлением операционной системы `Android` или `IOS` в качестве средства диагностики состояния пациента.
-   Микрокомпьютер `RaspberryPi` используется в качестве вычислительного хаба для сбора данных с датчиков и средств диагностики состояния пациента.
-   Облачная платформа `IBM Cloud Private` используется для реализации сервисов аналитической обработки и визуализации данных о пациентах в приватном медицинском учреждении (с возможностью полного доступа к персональной информации).
-   Блокчейн-платформа `Hyperledger Fabric` используется для реализации публичного распределенного реестра сервиса хранения деперсонифицированной информации.

Система работает следующим образом. 

Пациент использует медицинский прибор для измерения некоторых параметров состояния (артериального давления, уровня сахара в крови, пульса, и т.д). Возможно также использование диалоговой диагностической системы или чат-ботов, выявляющих и анализирующих состояние человека. Мы будем использовать мобильный телефон для сбора первичных данных. 

Далее, мобильный телефон передает данные через беспроводной интерфейс (мы используем беспроводную сеть WiFi) на вычислительных хаб (одноплатный компьютер `Raspberry Pi`).  На вычислительном хабе функционируют Node.js сервер, который выполняет первичную обработку данных, и, при необходимости ее деперсонализацию. 

Данные из вычислительного хаба передаются в облачную платформу `IBM Cloud Private`, в которой развернут сервисы хранения и визуализации данных. На основе этой информации врач может принять решение о проведении дополнительных процедур, выписке пациенту необходимых лекарство, дополнительной консультативной поддержки и прочих обоснованных действиях, вытекающих из истории наблюдений.

![Функциональная схема проекта](assets/hackathon04_2018.png)
**Функциональная схема проекта**


Для формировании истории наблюдений, используемых другими специалистами, а также сторонними участниками, деперсонализированная информация сохраняется в публичной blockchain платформе `Hyperledger Fabric`. Мы развернем кластер `Hyperledger Fabric` на публичной облачной платформе `IBM Cloud`.
 

****
## Оборудование и настройка компьютера разработчика <a name="12"></a>

В ходе хакатона организаторы предоставят участникам следующее оборудование:

* Микрокомпьютер Raspberry Pi 3B
* SD карта с предустановленной операционной системой Raspbian
* microUSB кабель и Ethernet кабели для подключения Raspberry Pi и компьютера разработчика к сети.

Требования к оборудованию разработкика:

* Учатник хакатона может выполнить все задания на компьютере в аудитории, однако рекомендуется использовать собственный ноутбук. Желательно использование операционной системы Linux (Ubuntu, Arch, CentOS, RHEL) или MacBook. В случае использования компьютера под управлением OC Windows рекомендуется воспользоваться готовым образом виртуальной машины, который можно найти на портале: [https://www.osboxes.org/ubuntu/](https://www.osboxes.org/ubuntu/).

* Желательно наличие смартфона под управлением ОС Android или IOS. При отсутствии смартфона участиники могут воспользоваться различными эмуляторами, которые будут упомянуты ниже.
****
# День 1 <a name="day1"></a>

## Raspberry Pi <a name="21"></a>
> Raspberry Pi — одноплатный компьютер размером с банковскую карту, изначально разработанный как бюджетная система для обучения информатике, 
впоследствии получивший намного более широкое применение и популярность, чем ожидали его авторы. 
>


![Raspberry PI](assets/raspberry01.jpg)
**Raspberry PI**

На плате размером с кредитную карту вы найдёте всё то, что можете найти в обычном персональном компьютере: процессор, оперативную память, 
разъёмы HDMI, USB, Ethernet, аналоговые аудио- и видеовыходы. Кроме того, на плате расположены 40 контактов ввода/вывода общего назначения. К 
ним вы сможете подключать периферию для взаимодействия с внешним миром: исполнительные устройства вроде реле и сервомоторов или же любые 
сенсоры; в общем всё, что работает от электричества.

Штатной операционной системой для Raspberry Pi является Linux. Она устанавливается на micro-SD карту, а та в свою очередь — в специальном 
слоте на плате. Если вы не знаете Linux, не стоит пугаться. Напротив: этот компьютер — прекрасная возможность во всём разобраться. Потерять 
данные или сильно напортачить с настройками не так страшно, ведь образ на SD-карте можно восстановить за считанные минуты. После этого можно 
продолжить эксперименты с чистого листа или с определённой контрольной точки.

****
## Порты и аппаратные интерфейсы <a name="22"></a>

Для подключения монитора или телевизора используются композитный видеовыход или разъём HDMI. Кроме того, заводские OEM ЖК-экраны могут быть 
подключены через интерфейс DSI.
Raspberry Pi 3 Model B предоставляет 4 USB-порта, объединённых внутренним хабом. К ним, помимо всего прочего, можно подключить клавиатуру и 
мышь.

В качестве низкоуровневых интерфейсов доступны:

- 40 портов ввода-вывода общего назначения
- UART (Serial)
- Шина I²C/TWI
- Шина SPI с селектором между двумя устройствами
- Пины питания: 3,3 В, 5 В и земля

Колонки или наушники могут быть подключены через стандартное гнездо для 3,5 мм джеков. Также звук может передаваться через интерфейс HDMI.
На Raspberry Pi Model B+ доступен Ethernet-адаптер на 10/100 Мбит с выходом на стандартное гнездо 8P8C (RJ45).

****
## Распиновка платы и подключение питания<a name="23"></a>

![Распиновка Raspberry](assets/raspberry02.jpg)
**Распиновка Raspberry**

Raspberry Pi Model B+ может быть запитана через microUSB-кабель или через пины питания.
Номинальное напряжение питания — 5 В. Компьютер потребляет до 800 мА без внешних устройств.
Аппаратный выключатель питания на плате отсутствует. Для включения компьютера достаточно просто подсоединить кабель питания. Для выключения 
используйте штатную функцию операционной системы.

****
## Разбор тестового примера<a name="25"></a> 

Берем Raspberry и аккуратно достаем карту памяти из прозрачного бокса.

![](assets/raspberry04.png)

Прежде всего нужно установить SD-карту с операционной системой Raspbian в соответствущее гнездо на плате Raspberry. В гнезде плата фиксируется 
благодаря блокирующему механизму. Для надежного закрепления нужно аккуратно вдавить пальцем карту в гнездо.

![](assets/raspberry05.png)

****
## Установка русской локализации <a name="250"></a> 

Русская локализация  (locale) позволи корректно отображать символы русского алфавита в консользных приложениях.
Для установки русской локализации выполните команду:

```sh
sudo raspi-config.
```

Выберите опцию `Localisation Options`. Далее опцию `Change locale`. И далее выберите локализацию `ru_RU.UTF-8`.

****
## Создание загрузочной SD карты <a name="251"></a> 

Если Вы решили использовать образ SD карты с операционной системой `Raspbian` c официального сайта Raspbery Pi [https://www.raspberrypi.org/downloads/raspbian/](https://www.raspberrypi.org/downloads/raspbian/) вам необходимо выполнить запись образа, например с помощью команды `dd`:

```sh
sudo dd bs=4M if=<путь к файлу img> of=/dev/mmcblk0
```

Обратите внимание, что указание неверного блочного устройства (например, /dev/sda вместо /dev/mmcblk0), приведет к удалению всех данных с Вашего компьютера. Убедитесь в безопасности Ваших действий, изучив таблицу дисков по команде `df -h` и `fdisk -l`.

Далее, после прошивки образа на карту, Вам необходимо разрешить использование службы ssh. Для этого скопируйте в корневой каталог раздела №1 SD-карты (устройство /dev/mmcblk0p1, /dev/sdb1 и т.д.), который имеет имя `boot`, файл [ssh](http://e-learning.bmstu.ru/moodle/pluginfile.php/6605/mod_resource/content/1/ssh)


****
## Настройка SSH соединения с Raspberry Pi <a name="26"></a>

Используя ОС Linux выполнить подключение к RPi можно следующим образом:

```sh
ssh pi@XX.XX.XX.XX
```

где XX.XX.XX.XX - ранее определенный ip адрес устройства. 

Если вы работаете в ОС Windows, то вам нужно воспользоваться программой Putty.
В поле Имя хоста указываем ip адрес Raspberry в сети, порт 22 и тип подключения SSH.

Пароль пользователя pi: **raspberry**

****
## Как узнать адрес Raspberry? <a name="27"></a>

* В Ubuntu выполните команду *sudo nmap –sN < ip-адрес компьютера >/< маска >*.  Пример:

 *sudo nmap -sN 192.168.10.0/24 -p 22*

 Результат работы команды:
 ```
 Nmap scan report for 192.168.10.23
 Host is up (-0.054s latency).

 PORT   STATE  SERVICE
 22/tcp open ssh
 MAC Address: B8:27:EB:4C:96:EE (Raspberry Pi Foundation)

 ```

* В Windows скачайте любое приложение, сканирующее адреса (к примеру, Advanced IP Scanner). Просканируйте сеть, в которой находится компьютер.

* В списке найдите устройство с именем, подобным “Raspberry PI".

Если вы обнаружите несколько микрокомпьютеров “Raspberry PI" в вашей сети, вам понадобится узнать т.н. MAC адрес устройства - уникальный идентификатор сетевого устройства, состоящий из 6 байт. Узнать его можно по команде:

```shell
$ ifconfig
$ eth0      Link encap:Ethernet  HWaddr `28:d2:44:69:2a:c8` 
```

Также вы можете определить вашу плату по уникальному имени устройства `hostname` в файле /etc/hosname:
```shell
$ cat /etc/hostame
$ host10
```
Для удобства мы написали последние 6 цифр MAC адреса на разъеме Ethernet вашей платы.
В исключительном случае вы можете обнаружить вашу плату опытным путем, отключая и подключая свой Pi к сети.





****
## Полезные команды для работы в ОС Raspbian <a name="28"></a>

-   "top" — запуск предустановленного в Raspbian диспетчера задач;
-   "sudo raspi-config" — запуск первоначального меню настроек;
-   "sudo passwd root" — создание пароля для пользователя root;
-   "startx" — запуск графической оболочки;
-   "sudo halt" — выключение RPi;
-   "logout" — выход из системы;
-   "sudo reboot" — перезагрузка RPi;
-   "cd" — переход в необходимую директорию, например, для перехода в директорию /etc/network/ - "cd /etc/network/"
-   "pwd" — путь до текущей директории;
-   "dir" — содержимое текущей директории;
-   "mkdir" — создание директории. Например, "mkdir /home/pitest/" создаст директорию "pitest";
-   "rmdir" — удаление директории. Например, "mdir /home/pitest/" - удаление директории "pitest";
-   "cat" — открыть файл для чтения. Например, "cat /etc/network/interfaces" покажет содержимое файла "interfaces";
-   "nano" — открыть файл для редактирования. Например, "nano
-   /etc/network/interfaces" откроет для редактирования файл "interfaces";
-   "ifconfig" — отобразит текущую конфигурацию сети;
-   "df" — выведет в консоли свободное и используемое дисковое пространство для всех разделов файловой системы;
-   "clear" — очистить экран терминала;
-   "Ctrl"+"Ins" — скопировать выделенное (текст);
-   "Shift"+"Ins" — вставить из буфера (текст);
-   "sudo" — выполнения команд c правами root пользователя. Например, это актуально, если вы зашли под пользователем "pi" и хотите из консоли 
отредактировать какой-нибудь системный файл - "sudo nano путь_до_файла";
-   "Ctrl"+"C" — остановка текущего действия/выход из консольного приложения;
-   "sudo apt-get update" — обновление списка доступных пакетов;
-   "sudo apt-get upgrade" — обновление установленных пакетов;
-   "sudo apt-get install" — установка необходимого пакета. Например, для
установки консольного браузера Links вводим "sudo apt-get install links".

****
##Установка программного обеспечения для точки доступа WiFi <a name="29"></a>
Для начала установим dhcp-сервер и программное обеспечение hostapd для организации беспроводной точки доступа

```sh
sudo apt-get update
sudo apt-get upgrade
sudo apt-get install hostapd dnsmasq
```

Выключаем установленные службы и перегружаем устройство:

```sh
sudo systemctl stop hostapd
sudo systemctl stop dnsmasq
sudo reboot
```


****
## Настройка dhcp-сервера <a name="2a"></a>

Правим файл /etc/dhcpd.conf:

```sh
sudo nano /etc/dhcpcd.conf
```

Добавляем в конец файла строки описание интерфейса wlan0:

```sh
interface wlan0
    static ip_address=192.168.4.1/24
    nohook wpa_supplicant
```

Далее рестартуем сервис `dhcpd`:


```sh
sudo service dhcpcd restart
```
Далее необходимо настроить службу dnsmasq, указав управляемый интерфейс и диапазон адресов. Оюратите внимание, что править настройки сети в файле `/etc/network/interfaces` не нужно, так как служба `dnsmasq` настраивает интерфейсы автоматически. Сохраним оригинальный файл настроек и создадим новый:

```sh
sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig
sudo nano /etc/dnsmasq.conf
```

В новый файл добавим следующие строки:

```sh
interface=wlan0      # Use the require wireless interface - usually wlan0
  dhcp-range=192.168.4.2,192.168.4.20,255.255.255.0,24h
```

****
## Настройка точки доступа WiFi <a name="2b"></a>


Далее устанавливаем настройки точки доступа `hostapd`. Создадим новый кофигурацийний файл:

```sh
sudo nano /etc/hostapd/hostapd.conf
```

В файл запишем следующие строки:

```sh
interface=wlan0
driver=nl80211
ssid=!!!Укажите ваш ssid!!!
hw_mode=g
channel=7
wmm_enabled=0
macaddr_acl=0
auth_algs=1
ignore_broadcast_ssid=0
wpa=2
wpa_passphrase=!!!Укажите ваш пароль!!!
wpa_key_mgmt=WPA-PSK
wpa_pairwise=TKIP
rsn_pairwise=CCMP
```

Сохраняем файл.

Разрешаем использование конфигурационного файл:

```sh
sudo nano /etc/default/hostapd
```

Правим строку:

```sh
DAEMON_CONF="/etc/hostapd/hostapd.conf"
```

Сохраняем файл и запускаем службы hostapd и dnsmasq.

```sh
sudo systemctl start hostapd
sudo systemctl start dnsmasq
```


Запускаем точку доступа:

```sh
sudo /usr/sbin/hostapd /etc/hostapd/hostapd.conf
```

После этого указанная Вами точка доступа должна появиться в списке доступных WiFi сетей. Вы можете подключить ваш Raspberry Pi к сети Internet кабелем Ethernet.
Если на ноутбуке или смартфоне, подключенном к Raspberry Pi удается загрузить страницу в браузере, настройка выполнено верно. 


****
## Настройка NAT (Network Address Translation) и тестирование <a name="2c"></a>

Установка NAT позволит многим клиентам подключаться к WiFi и получать все данные через единую Ethernet IP.

```sh
sudo nano /etc/sysctl.conf
```

Раскомментируем строку:

```sh
net.ipv4.ip_forward=1. 
```

Разрешаем форвардинг пакетов ip4.

```sh
sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
```

Запускаем следующие команды для настройки сетевой трансляции между ethernet портом eth0 и wifi портом wlan0. 

```sh
sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
sudo iptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT
```

Проверяем таблицы:

```sh
sudo iptables -t nat -S
sudo iptables -S
```

Сохраняем настройки iptables и разрешаем автоматическую загрузку настроек при загрузке:

```sh
sudo sh -c "iptables-save > /etc/iptables.ipv4.nat"
```

Настроим автоматический запуск WiFi при загрузке Raspbery Pi:

```sh
sudo nano /etc/rc.local
```

Добавьте строку загрузки таблицы:

```sh
iptables-restore "/etc/iptables.ipv4.nat"
```

Перегружаем систему:

```sh
sudo reboot
```


****
## Установка Node.js на Raspberry Pi <a name="2d"></a>

В этом задании нам необходимо разработать и запустить клиент-серверного приложение, используя Raspberry Pi в качестве сервера, компьютер или смартфон в качестве клиента.
Клиент и сервер будут находиться в одной локальной сети WiFi, настроенной нами ранее.

В качестве серверного узла выступает (Node.js + Express),
в качестве клиента - браузер (js + html).


Для этого выполните команды для установки Node.js:

```sh
sudo apt-get update
sudo apt-get install nodejs
sudo apt-get install npm
sudo apt install nodejs-legacy
```

Проверьте, установились ли пакеты:
```sh
node -v
v8.11.1
npm -v
5.3.0
```

Если пакет `npm` (Node.js Package Manager) не установлен и не показывает версию,
то необходимо его установить отдельно командой `sudo apt-get install npm`

## Запуск hello-сервера на Raspberry Pi <a name="2e"></a>

1. Создайте папку `hello`: ```sh mkdir hello```
2. Перейдите в нее и выполните команду `npm init` (все опции оставлять по умолчанию)
В вашей папке появился файл `package.json`, в нем будут храниться зависимости проекта и параметры запуска.
3. Далее необходимо установить веб-фреймворк `Express` для обработки запросов, маршрутизации и раздачи статики.
`npm install express --save` (`--save` сохранит зависимость в `package .json`, в нем появилась строчка `"dependencies": {"express": "^4.16.4"}`)

```json
{
  "name": "hello",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC",
  "dependencies": {
    "express": "^4.16.4"
  }
}
```
4. Создайте файл с кодом сервера `index.js`

```js
"use strict";

// подключаем фреймвок express
let express = require('express');
let app = express();

// разрешаем междоменные запросы
app.use(function(req, res, next) {
    res.header("Access-Control-Allow-Origin", "*");
    res.header("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
    res.header("Cache-Control", "no-cache, no-store, must-revalidate");
    next();
});

// hello-GET, вывод сообщения в браузере 'Hello Pi'
app.get('/api/hello', function (req, res) {
    res.send('Hello Pi');
});

// слушаем на порту 5055 или другом свободном
let port = process.env.PORT || 5055;
app.listen(port);
console.log("Server works on port " + port);
```
5. Выполните команду для запуска скрипта `node index.js` (в терминале должно появиться сообщение, что сервер работает)

**Задание: Определите URL для проверки работоспособности вашего сервера.**

Если вы сделали все верно, должно появиться сообщение `Hello Pi`

> Можно в `package.json` добавить скрипт `"start":"node index.js"` и запускать приложение командой `npm start`

> Чтобы выключить сервер, в его терминале используйте сочетание клавиш `Ctrl + C`



## Подготовка к запуску стартовых приложений <a name="2f"></a>

В следующем задании Вам понадобятся компьютер под управление ОС Linux с браузером и сервер (Raspberry Pi).
На клиентском устройстве необходимо повторить предыдущие шаги установки Node.js  и веб-фреймворка Express, так как на клиенте надо будет иметь сервер со статикой для веб-интерфейса!

Скачать примеры из репозитория на клиентский и серверный узел [git репозиторий](https://github.com/alexbmstu/2018.git)
На Raspberry Pi понадобится папка `server`, на клиенте - `client`

На сервере (Raspberry Pi):

```sh
cd ~
mkdir nodejs
cd ./nodejs
wget https://github.com/alexbmstu/2018/raw/master/src/server.zip
unzip server.zip
```

Аналогичные действие выпоните на клиенте (ноутбуке или смартфоне), заменив `server` на `client`

### Действия на сервере <a name="2f01"></a>
1. На Raspberry Pi перейдите в папку `server`
2. Для установки зависимостей выполните `npm install`
3. Для запуска сервера выполните `npm start`
4. Сервер готов к запросам

### Действия на клиенте <a name="2f02"></a>
1. На устройстве перейдите в папку `client`
2. Для установки зависимостей выполните `npm install`
3. Для запуска сервера выполните `npm start`
4. Для перехода к веб-интерфейсу в браузере перейдите по адресу сервера `http://localhost:5007/`

> Для тестирования веб-интерфейса поднимите и основной сервер на вашем компьютере

**Задание: поменять url запросов и порты работы серверов таким образом, чтобы запросы можно было пересылать с веб-интерфейса на сервер-обработчик Raspberry Pi**

****
# День 2 <a name="day2"></a>


## Сбор фитнес и медицинских данных с помощью мобильных приложений <a name="31"></a>

В нашем хакатоне мы не имеем возможности использовать дорогостоящее медицинское оборудование, поэтому мы будет прототипировать систему на основе фитнес данных, полученных с помощью Ваших смартфонов.
В этой части нашего конкурса Вам предстоит разработать мобильное приложение, позволяющее собирать данные и передавать их в разрбатывемую систему через вычислительный хаб Raspberry Pi.

Вы можете использовать один из двух вариантов:

* Разработка в ОС Android.
* Разработка в IOS.

Подсистема сбора данных будет работать следующим образом. На смартфоне должны быть установлены приложения Google Fit и Apple Health, которые позволяют собирать различные фитнес-данные: активность, пройденный путь, количество шагов, пульс. Ондако при наличии специального оборудования и сенсоров, подключаемых к смарфону или передаваемых по беспроводным интерфейсам, эти приложения позволяют фиксировать и анализировать любые медицинские данные, а также передавать их по специальным API другим приложениям. Стоит отметить, что в настоящее время проекты динамично развиваются, поэтому не всегда представляется возможным быстро прототипировать проект из-зи наличия ошибок, отсутствия подробной документации и пр. Поэтому мы поступим другим образом: мы будем использовать накопленную статистику приложений, для чего мы разработаем собственное мобильное приложения, агрегирующее даные медицинского характера. 

## Мобильный телефон с ОС Android <a name="32"></a>

### Установка программного обеспечения для разработки мобильных приложений на OS Android <a name="321"></a>

Если вы решили делать приложение для Android, вам потребуются следующие компоненты:

* AndroidStudio
* Нужный нам SDK для AndroidStudio
* Android телефон
* Google аккаунт
* Приложение Google Fit
* Данные в Google Fit
Теперь рассмотрим подробнее каждый элемент отдельно.

#### Установка Android Studio <a name="3211"></a>

Переходим на сайт [https://developer.android.com/studio/](https://developer.android.com/studio/)

Скачиваем и устанавливаем `Android Studio` на компьютер (желательно исопльзовать ОС Linux). В ходе установки загружаем все предлагаемые модули.


#### Установка версии SDK <a name="3212"></a>

Определяем версию ОС Вашего телефона.

![Определение версии ОС Android](assets/image4-56.png)
**Распиновка Raspberry**

Запускаем студию и переходим в настройки. 

![Установка Android Studio](assets/SDK.png)
**Установка Android Studio**

Далее необходимо скачать нужный SDK из соответствующего раздела меню.

![Выбор версии ОС](assets/Android-SDK-24.4.1-Latest-Version-Download.png)
**Выбор версии ОС**

#### Android телефон, Google аккаунт, Приложение Google Fit <a name="3213"></a>


Вам необходимо создать аккаунт для вашего проекта. Зайти в него на телефоне и установить приложение `Google Fit` с помощью `Google Play Market`.

Далее запустите приложение и войдите под созданным аккаунтом. Теперь вам можно начать собирать данные, например, начав ходить по аудитории.  Проверьте, что данные корректно фиксируются в приложении `GoogleFit`.

![Приложение Google Fit](assets/GoogleFit.png)
**Приложение Google Fit**

### Сборка и запуск тестового приложения Android <a name="322"></a>


Данные о пульсе можно брать из приложения Accurate Heart Rate Monitor

![](assets/Android_html_14f3eb2f8656de30.png)

После установки приложения заходим в настройки и устанавливаем флаг интеграции с Google Fit

![](assets/Android_html_ea1277131a4ca99b.png)

Далее измеряем пульс. Вскоре эти данные должны появиться в облаке Google.

Для получения данных о сне устанавливаем Runtastic Sleep Better

![](assets/Android_html_5e94403be6fa9409.png)

Интеграция автоматическая

Для получения данных о питании устанавливаем myfitnesspal

![](assets/Android_html_3379c061e26f43b.png)


Скачайте тестовый проект MyApplication. Для этого скачайте [git репозиторий](https://github.com/alexbmstu/2018.git)

Вам понадобится архив в папке `./scr`. Распакуйте архив MyApplication4-2.zip.

Открываем папку с проектом в андройд студии.

![](assets/Android_html_8bcd05d31e182942.png)

Синхронизируем Gradle

![](assets/Android_html_1d748bdfffa9b2c0.png)

Нужна эта иконка

![](assets/Android_html_c98922279a04202f.png)

Далее подключаем телефон шнурок к компу

На телефоне открываем настройки и ищем страницу информации о ОС (о телефоне)

Много раз нажимаем на версию прошивки, пока не увидим сообщение о том что стали разработчиком

![](assets/Android_html_c6fce88d8df6496c.gif)

Далее где-то в настройках у вас появится пункт «Для разработчиков»

![](assets/Android_html_36c8dbf4b65f72cf.gif)

Открываем этот пункт, включаем режим разработчика и включаем все что связано с отладкой по USB

![](assets/Android_html_36a60ff32714ad68.gif) ![](assets/Android_html_9ef7d8303dc304cd.gif)

Далее идем в настройки проекта

![](assets/Android_html_46738d97691ddd88.png)

Устанавливаем минимальную версию SDK не ниже чем версия на вашем телефоне

![](assets/Android_html_b154999772502f4f.png)

Пробуем запустить приложение

![](assets/Android_html_a076265319378453.png)

В окне выбора устройств выбираем свой телефон

![](assets/Android_html_b42aea9b179417a9.png)

Далее необходимо настроить консоль разработчика

Идем на сайт

[https://console.developers.google.com](https://console.developers.google.com/)

В окне выбора проектов создаем новый

![](assets/Android_html_b9419a7dd5c11d8e.png)

Вводим имя проекта и сохраняем

В окне выбора проектов выбираем созданный проект

![](assets/Android_html_208dccb66d9c7037.png)

![](assets/Android_html_561c1afc02a2744e.png)

Жмем включить Api и Сервисы

В поиске вводим Fit и выбираем Fitness Api.

![](assets/Android_html_d835e4401ccaded6.png)

На странице Api жмем включить

Теперь нужно создать учетные данные

![](assets/Android_html_4228554e8cda4eb7.png)

или так

![](assets/Android_html_6cc240583ff1ac57.png)

На странице учетных данных жмем создать

![](assets/Android_html_36f7d18055e40435.png)

Заполняем первую форму

![](assets/Android_html_a4ca26a14681e8f5.png)

Жмем выбор типа учетных данных

Открываем окно Gradle

![](assets/Android_html_f079c6322684ab37.png)

Открываем Signing Report

![](assets/Android_html_f66a3f1cf94e57a1.png)

Дважды кликаем на него

В консоли нам напишет

![](assets/Android_html_f867acd3beeb5659.png)

Нас интересует этот блок

![](assets/Android_html_4c1ae61136bdf6d1.png)

Копируем SHA1 ключ

A7:fvdnvldfvnldfnvkldnvlkdnfvndfklvndlfnvkdfnvlkdnklfnvld

Открываем файл манифеста

![](assets/Android_html_193a41c49336dd86.png)

Ищем название пакета

package="com.example.alexdark.myapplication4"

![](assets/Android_html_5fb18a465ab137a4.png)

Жмем создать идентификатор клиента

Далее заполняем форму

![](assets/Android_html_e1576d155732e85.png)

Скачиваем ClientID

![](assets/Android_html_5e05523ea8ee76c6.png)

Это  строка  вида

чтоТоТамСекретное.apps.googleusercontent.com

Открываем файл констант

![](assets/Android_html_e88f7068271090a.png)

Меняем строчку

`<string name="server_client_id">-- </string>`

Вставляем свой ключ

Теперь еще раз запускаем приложение на устройстве и наслаждаемся его работой.

При запуске ждем когда произойдет подключение к серваку

Когда это произойдет жмем кнопку GetData

Важный код описан комментариями

  
Данные которые можно запрашивать из GoogleFit приведены тут

[https://developers.google.com/android/reference/com/google/android/gms/fitness/data/DataType](https://developers.google.com/android/reference/com/google/android/gms/fitness/data/DataType)

Чтобы получить доступ к ряду значений необходимо при создании клиента запрашивать дополнительные разрешения
```

mGoogleApiClient = new GoogleApiClient.Builder(this)
.addApi(Fitness._HISTORY_API_)
.addScope(new Scope(Scopes._FITNESS_ACTIVITY_READ_WRITE_))
.addScope(new Scope(Scopes._FITNESS_BODY_READ_WRITE_))
.addScope(new Scope(Scopes._FITNESS_NUTRITION_READ_))
.addConnectionCallbacks(this)
.enableAutoManage(this, 0, this)
.build();
```
Подробно об этом написано тут

https://developers.google.com/android/reference/com/google/android/gms/common/Scopes

Если вы хотите анализировать активность то расшифровка типов приведена тут

[https://developers.google.com/fit/rest/v1/reference/activity-types](https://developers.google.com/fit/rest/v1/reference/activity-types)

Если вам нужно получать из облака данные которых там нет, можно попробовать записать их туда самим. Google Fit позволяет записывать данные в облако. Тут очевидного ответа а как нет. Можно выделить лишь общий принцип

1.  Создаем дата сорс

2.  Создаем дата сет из сорса

3.  Создаем измерение

4.  Заполняем измерение данными

5.  Кладем измерение в дата сет

6.  Отправляем дата сет

Основные сложности будут с шагом 4\. Каждый дата поинт для разных типов данных имеет свою специфику заполнения. Это вам придется гуглить. В проекте есть пример для создания активити. Это самый простой пример. Желательно конечно, чтобы вы нашли мобильное приложение, которое интегрируется с фитом.

### Получение и обработка данных на nodejs сервере Raspberry Pi  <a name="331"></a>

Для того, чтобы протестировать получение данных вычислительным хабом RaspberryPi, необходимо поменять код приложения сервера nodejs. Для этого добавьте в код `index.js` в папке `./routes` следующий код:

```js 

router.post('/data', function (req, res) {
    console.log(req);
    res.send();
});

router.post('/step', function (req, res) {
    res.send();
    console.log('********')
    console.log('steps')
    console.log(req.body['start'])
    console.log(req.body['value'])

});

router.post('/pulse', function (req, res) {
    res.send();
    console.log('********')
    console.log('pulse')
    console.log(req.body['start'])
    console.log(req.body['value'])

});

router.post('/activity', function (req, res) {
    res.send();
    console.log('********')
    console.log('activity')
    console.log(req.body['start'])
    console.log(req.body['activity'])
    console.log(req.body['duration'])
    console.log(req.body['segments'])
});

router.post('/nutrition', function (req, res) {
    res.send();
    console.log('********')
    console.log('nutrition')
    console.log(req.body['start']);
    console.log(req.body['mealType']);
    console.log(req.body['calcium']);
    console.log(req.body['calories']);
    console.log(req.body['carbsTotal']);
    console.log(req.body['cholesterol']);
    console.log(req.body['dietaryFiber']);
    console.log(req.body['fatMonounsaturated']);
    console.log(req.body['fatPolyunsaturated']);
    console.log(req.body['fatSaturated']);
    console.log(req.body['fatTotal']);
    console.log(req.body['fatTrans']);
    console.log(req.body['iron']);
    console.log(req.body['potassium']);
    console.log(req.body['protein']);
    console.log(req.body['sodium']);
    console.log(req.body['sugar']);
    console.log(req.body['vitamin_c']);
});

```

Проверьте, что в логах запущенного nodejs появляются сообщения с данными от нашего приложения.

## Мобильный телефон с iOS <a name="33"></a>

### Установка программного обеспечения для разработки мобильных приложений на iOS <a name="331"></a>

Для того, чтобы разрабатывать мобильные приложения для `iOS` необходим компьютер старше 2013 года с операционной системой `maсOS Mojave`. На компьютер необходимо установить IDE для разработки `iOS` приложений – Xcode.

Xcode (версия 10) можно скачать в магазине App Store на компьютере с macOS Mojave :

![](assets/iOS_html_2d196317aa6bb516.png)

После установки, IDE отобразится в меню приложений:

![](assets/iOS_html_95debbd82af313ff.png)

Прежде чем писать приложения под `iOS` и отправлять их на сервер, необходимо их подготовить и собрать при помощи `iPhone`.

Любые параметры, связанные со здоровьем в `iPhone`, как правило передаются в системное приложение `Health`, которое выглядит так:

![](assets/iOS_html_c06e4f2a185a5031.png)

Подробное описание можно найти на сайте: [https://www.apple.com/ru/ios/health/](https://www.apple.com/ru/ios/health/)

Во время работы с нашим примером мы будем собирать следующие данные: пульс, медитацию, сон и отдых (в приложении называется осознанность), шаги, калории и другие параметры питания.

Чтобы собирать данные о пульсе необходимо:

1) Установить приложение

![](assets/iOS_html_b818428146844971.jpg)

2) Зайти в приложение Cardiio

![](assets/iOS_html_582217324c415d5c.jpg)

3) Зайти в настройки и проскроллить до секции `Apple Health`, после чего включить интеграцию с `Health`

![](assets/iOS_html_a66391c66f8a8299.jpg)

4) После измерения пульса, данные можно будет увидеть в `Health`

![](assets/iOS_html_2f275c92138b7eca.jpg)

Чтобы собирать данные с шагомера и пройденного расстояния не нужно ставить никаких дополнительных приложений, все данные уже находятся в `Health`:

![](assets/iOS_html_4b6eb75e2df605fe.jpg)

Чтобы собирать данные о питании необходимо проделать следующие шаги:

1) Установить приложение `FatSecret`

![](assets/iOS_html_61a282a276905974.jpg)

2) Зайти в настройки приложения и включить интеграцию с `Health`

![](assets/iOS_html_ebea3cd28a29ae1c.jpg)

3) Добавить прием пищи в приложение

![](assets/iOS_html_7af205cc846dc391.jpg)

4) После этого вся информации о питании будет доступна в `Health`

![](assets/iOS_html_6b91a9fa11f1d15f.jpg)

Для того чтобы собирать данные о медитации и отдыхе необходимо проделать следующие шаги:

1) Установить приложение `Relax Melodies`

![](assets/iOS_html_3078659d9baa9bab.jpg)

2) Включить в настройках интеграцию с `Health`

![](assets/iOS_html_c488a74b92455944.jpg)

3) Далее после медитации под какую-нибудь бесплатную мелодию данные о медитации отправятся в `Health`

![](assets/iOS_html_141b413dd1351942.jpg)


### Установка и запуск приложения <a name="332"></a>


Скачайте тестовый проект BMSTU2018. Для этого скачайте [git репозиторий](https://github.com/alexbmstu/2018.git)

Вам понадобится архив в папке `./scr`. Распакуйте архив BMSTU2018.zip.

Далее вам необходимо открыть файл с разрешением xcworkspace BMSTU.

Загрузите приложение на девайс.



### Получение и обработка данных на nodejs сервере Raspberry Pi  <a name="333"></a>

Для того, чтобы протестировать получение данных вычислительным хабом RaspberryPi, необходимо поменять код приложения сервера nodejs. Для этого добавьте в код `index.js` в папке `./routes` следующий код:

```js 
router.post('/data', function (req, res) {
    res.send();
    console.log(req.body['parameter']);
    console.log(req.body['value']);
});
```

Проверьте, что в логах запущенного nodejs появляются сообщения с данными от нашего приложения.





****
# День 3 <a name="day3"></a>


## Обзор IBM Cloud Private <a name="41"></a>

**IBM Cloud Private** является частной облачной платформой для разработки и выполнения рабочих нагрузок на локальных серверах предприятий. Это интегрированная среда, которая позволяет вам разрабатывать, развертывать и управлять локальными облачными приложениями, расположенными внутри инфраструктуры ЦОД, что позволяет в большей степени защитить данные. Он включает в себя контейнерный оркестратор Kubernetes, частный репозиторий образов, консоль управления и различные системы мониторинга.

### Что такое приватные облака? <a name="411"></a>

Частное облако - это облачная вычислительная модель, предназначенная исключительно для одной организации. К ее управлению могут быть допущены только доверенные лица, имеющию полномочия по доступу в частную сеть предприятия. Частное облако предлагает преимущества публичного облака, включая быстрое развертывание и масштабируемость, а также простоту использования и эластичность, но также обеспечивает больший контроль, повышенную производительность, предсказуемые затраты, более строгую безопасность и гибкие возможности управления. 


### Архитектура IBM Cloud Private <a name="412"></a>

Основными элементами **ICP** являются:

* Система управления Linux-контейнерами **Docker** - программное обеспечение для автоматизации развёртывания и управления приложениями в среде виртуализации на уровне операционной системы. Позволяет «упаковать» приложение со всем его окружением и зависимостями в контейнер, который может быть перенесён на любую Linux-систему с поддержкой cgroups в ядре, а также предоставляет среду по управлению контейнерами.

* Система оркестрации Linux-контейнеров **Kubernetes** -  открытое программное обеспечение для автоматизации развёртывания, масштабирования и управления контейнеризированными приложениями. Поддерживает основные технологии контейнеризации, включая Docker, rkt, также возможна поддержка технологий аппаратной виртуализации. 

![Architecture](assets/ICP_architecture.png)

### Терминология <a name="413"></a>

**Kubectl:** - CLI (интерфейс командной строки) для Kubernetes

**Мастер-нода** [master node] - главный компьютер, который управляет нодами и является точкой входа [entry point] для всех административных задач.

**Рабочая нода** [worker node] - Это рабочий сервер в Kubernetes, на котором запускаются Docker контейнеры. Рабочие ноды управляются Мастер-нодой. 

**Kubelet** - агент, запущенный на ноде, который следит за выполнением задач в контейнерах.

На наших рисунках кое-чего не хватает. Kubernetes управляет контейнерами не напрямую, а через поды. Поды описывают, как выполнять один контейнер или несколько одновременно.

**Развертывание** [deployment] - описание инфраструктуры некоторого решения, запускаемого в виде контейнеров. Развертывание может увеличивать или сокращать количество запущеннных инстансов приложений для изменения параметров производительности.  Развертывание обычно описывается в виде `yaml` файла. Например развертывание сервиса балансировки сетевого траффика выглядит следующим образом:

```yaml
	apiVersion: apps/v1
	kind: Deployment
	metadata:
	  name: nginx-deployment
	  labels:
	    app: nginx
	spec:
	  replicas: 3
	  selector:
	    matchLabels:
	      app: nginx
	  template:
	    metadata:
	      labels:
		app: nginx
	    spec:
	      containers:
	      - name: nginx
		image: nginx:1.15.4
		ports:
		- containerPort: 80
```
 
**Под** - это один экземпляр развертывания, обладающий своим уникальным IP адресом в кластере. У одного развертывания может быть несколько подов. При удалении Пода все данные удаляются, поэтому для долговременного данных и их исопльзования в других подах следует подключать внешние тома или сетевые хранилища. 


**Секрет** [secret] — это объект, который хранит конфиденциальные данные, например, имена пользователей и пароли.

**Сервис** - поддерживаемый системой оркестрации ресурс, обеспечивающий сетевой доступ к подам. В Kubernetes определены три типа сервисов:

1. IP кластера [ClusterIP]

	– Развертывание доступно только внутри кластера.
	– Каждому развертыванию присваивается внутренний IP-адрес кластера.
	– Трафик распределяется между подами развертывания через балансировку нагрузки.

2. Порт ноды [node port]

	– Развертывание доступно внутри кластера.
	– Развертывание привязано к порту мастер-ноды.
	– Каждая нода будет проксировать этот порт для вашего сервиса.
	– Сервис доступен по http(s)://:/.
	–Трафик распределяется между подами развертывания через балансировку нагрузки.

3. Балансировщик нагрузки [load balancer]

	– Развертывание получает общедоступный IP-адрес.
	– Сервис доступен по http(s)://:<80||42>/.
	–Трафик распределяется между подами развертывания через балансировку нагрузки.

 

[Подробные учебные материалы на английском языке](https://github.com/phthom/IBMCloudPrivate)

## Доступ к web консоли управления IBM Cloud Private <a name="42"></a>

Доступ к ICP МГТУ осуществляется по следующим адресам:

* https://195.19.40.201:8443

или

* https://icp.bmstu.ru:8443

![](assets/loginicp.png)

Для доступа к Web интерфейсу Вы должны получить логин и пароль от преподавателя.

Web-консоль управления может исопльзоваться для мониторина ресурсов, создания различных сервисов и развертываний, запуска подов и пр.
Вместе с этим возможен командный способ доступа ко всем ресурсам облака с помощью утилит `kebectl`, `ibmcloud / bx pr`, `helm` и `docker`.


## Доступ к IBM Cloud Private с помощью консольных утилит<a name="43"></a>

Для выполнения заданий хакатона понадобится установить на вашем локальном компьютере `docker`, консоль `bx` и плагин `pr`, а ткже консоль `kubectl`.

### Установка консолей <a name="431"></a>

Выполните в консоли команду:

`curl -sL https://ibm.biz/idt-installer | bash`

Далее следуйте инструкциям по установке. 

Для non-Linux систем смотрите подробную инструкцию [тут](https://console.bluemix.net/docs/cli/index.html#overview).

Проверьте работу плагина `bx`:

`bx --help`

### Установка плагина ICP<a name="432"></a>

Далее перейдите в web-консоли на страницу установки плагинов CLI: Menu > Command Line Tools > Cloud Private CLI. Скачайте файл плагина, соответствующий вашей операционной системе.

Для установки скачанного плагина в `ОС Linux amd64` используйте команду:

`bx plugin install <path_to_installer>/icp-linux-amd64`

Для других ОС команды можно узнать [тут](https://www.ibm.com/support/knowledgecenter/SSBS6K_2.1.0.3/manage_cluster/install_cli.html)


Проверьте, что плагин IBM Cloud Private работает:

`bx pr --help`

Выполним вход на наш кластер ICP:

`bx pr login -a https://icp.bmstu.ru:8443 --skip-ssl-validation`


### Получение доступа консоли kubectl к ICP <a name="433"></a>

Далее Вам необходимо получить токен для доступа к ICP. Токен валиден только в течении 12 часов, поэтому мы автоматизируем процесс получения токена и валидации доступа. Создайте файл `connectICP.sh` со следующим содержанием:

```sh
CLUSTERNAME=bmstu.ru
ACCESS_IP=195.19.40.201
USERNAME=xxxxxxxxx
PASSWD=xxxxxxxx

token=$(curl -s -k -H "Content-Type: application/x-www-form-urlencoded;charset=UTF-8" -d "grant_type=password&username=$USERNAME&password=$PASSWD&scope=openid" https://$ACCESS_IP:8443/idprovider/v1/auth/identitytoken --insecure | jq .id_token | awk  -F '"' '{print $2}')

kubectl config set-cluster icp.$CLUSTERNAME --server=https://$ACCESS_IP:8001 --insecure-skip-tls-verify=true
kubectl config set-context icp.$CLUSTERNAME-context --cluster=icp.$CLUSTERNAME
kubectl config set-credentials $USERNAME --token=$token
kubectl config set-context icp.$CLUSTERNAME-context --user=$USERNAME --namespace=$USERNAME
kubectl config use-context icp.$CLUSTERNAME-context
```

Укажите в файле Ваш логин и пароль в полях `USERNAME=` и `PASSWD=`. Сохраните файл.

Далее необходимо разрешить запуск скрипта:

`chmod +x connectICP.sh`

Запустите скрипт:

`./connectICP.sh`

В итоге вы должны получить следующий ответ:

```sh
Cluster "cluster.local" set.
Context "cluster.local-context" modified.
User "team00" set.
Context "cluster.local-context" modified.
Switched to context "cluster.local-context".
```

Выполните вход на сервер ICP:

`kubectl version --short`

Более подробно о дуступе и получении токена вы можете прочитать [тут](https://www.ibm.com/support/knowledgecenter/SSBS6K_2.1.0.3/manage_cluster/cfc_cli.html)

### Доступ docker к ICP <a name="434"></a>

Укажите в файле `/etc/hosts` путь к серверу `ICP`:

`195.19.40.201 icp.bmstu.ru`

Создайте на Вашем компьютере папку для хранения ключей:

`sudo mkdir /etc/docker/certs.d/icp.bmstu.ru:8500/`

Для доступа к кластеру с помощь локального docker менеджера вам понадобится `ca.crt`. Ключ будет послан Вам по почте преподавателем.

Положите полученный ключ в папку `/etc/docker/certs.d/icp.bmstu.ru:8500/`

На клиентском компьютере перезапустите службу Docker:

`sudo service docker restart`

Войдите в свой личный реестр образов.

`sudo docker login icp.bmstu.ru:8500`

В ответ вы должны получить следующее сообщение:

```
Authenticating with existing credentials...
WARNING! Your password will be stored unencrypted in /home/team00/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
```

## Создание docker образа и его развертывание на ICP <a name="44"></a>

В этом разделе мы создадим и настроим docker образ для развертывания в ICP. Далее мы запустим развернутый образ и создадим работающий "под". Доступ к поду будет осуществляться по `ssh`.

## Создание docker образа <a name="441"></a>

Создайте на своем локальном компьютере файл с именем `Dockerfile` со следующим содержимым:

```
FROM ubuntu:16.04

RUN apt-get update && apt-get install -y openssh-server
RUN mkdir /var/run/sshd
RUN echo 'root:hackathon' | chpasswd
RUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config

RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

ENV NOTVISIBLE "in users profile"
RUN echo "export VISIBLE=now" >> /etc/profile

EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]
```

Файл описывает контейнер, основанный на `Ubuntu Linux 16.04`. Далее при создании образа будет выполнена установка openssh сервера, а также разрешен вход по ssh пользователю root и паролю hackathon. Вы можете поменять пароль для доступа к  машине.

Выполните сборку образа:

`sudo docker build -t hack_sshd .`

Далее роверьте работоспособность образа на локальном компьютере:

```
sudo docker run -d -P --name test_sshd hack_sshd
sudo docker port test_sshd 22
```

В итоге контейнер будет запущен и Вам будет выдан ip адрес и порт:

`0.0.0.0:49154`

Обратите внимание, что адрес `0.0.0.0` не является адресом контейнера. Вам нужно узнать параметры сети docker по команде `ifconfig`

```
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        inet6 fe80::42:b8ff:feda:5831  prefixlen 64  scopeid 0x20<link>
        ether 02:42:b8:da:58:31  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 68  bytes 11048 (11.0 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

Зайдите в контейнер по команде:

```
ssh root@172.17.0.1 -p 32768
The authenticity of host '[172.17.0.1]:32768 ([172.17.0.1]:32768)' can't be established.
ECDSA key fingerprint is SHA256:S4g5OT66u04YzEY9ck8S0n29HJ728CmeRFVKy0OhBc8.
Are you sure you want to continue connecting (yes/no)? 
```

Выйдите из сессии ssh по команде `exit`. Остановите образ на локальном компьютера, т.к. далее мы будем использовать ICP.

```sh
sudo docker container stop test_sshd
``` 

## Развертывание docker образа в ICP <a name="442"></a>

Далее подготовим образ к передаче в репозиторий ICP. Укажем имя образа и репозиторий (вам необходимо указать доступный вам namespace вместо `team00`):

`sudo docker tag hack_sshd icp.bmstu.ru:8500/team00/hack_sshd`

Далее передаем образ в ICP:

`sudo docker push icp.bmstu.ru:8500/team00/hack_sshd`

Теперь образ находится на сервере и Вы можете обнаружить его на странице Images:

![](/assets/namespace.png)

Аналогичный результат вы получите, использовав команду:

`kubectl get images`

Далее уточним активный namespace:

`kubectl config current-context`

Если не установлен нужный нам `namespace`=`ваш логин`, установим его:

`kubectl config set-context my-context --namespace=team00`

Теперь мы можем развернуть образ на кластере ICP:

`kubectl run team00ubuntu --image=icp.bmstu.ru:8500/team00/hack_sshd`

Проверить выполнение команды можно следующим образом:

```sh
kubectl get pods
AME                            READY     STATUS    RESTARTS   AGE
team00ubuntu-67bfd95cd9-94b65   1/1       Running   0          11s
```

Далее необходимо разрешить форвардинг портов к нашему Поду. Для этого используем команду `expose`:

`kubectl expose deployment team00ubuntu --name=team00_ssh --type=LoadBalancer --port=22 --target-port=22`

Осталось узнать порт, который использовал Kubernetes для форвардинга в порт 22 нашего Пода:

```
kubectl get svc
NAME                       TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
team00_ssh                     LoadBalancer   10.0.0.126   <pending>     22:30646/TCP   1m
```

Нам был выделен порт 30646. Теперь мы можем обратиться к нашему контейнеру:

```
ssh root@195.19.40.201 -p 30646
The authenticity of host '[195.19.40.201]:30646 ([195.19.40.201]:30646)' can't be established.
ECDSA key fingerprint is SHA256:S4g5OT66u04YzEY9ck8S0n29HJ728CmeRFVKy0OhBc8.
Are you sure you want to continue connecting (yes/no)? 
```
Подробнее об использовании docker в ICP вы можете прочитать [тут](https://github.com/phthom/IBMCloudPrivate/blob/master/2-DockerLab.md)

Подробнее о развертывании и конфигурировании сервисов Kubernetes вы можете прочитать [тут](https://kubernetes.io/docs/concepts/services-networking/service/#multi-port-services)


## Запуск Пода с использованием yaml конфигурации <a name="443"></a>

Под можно создать как из обаза, сохраненного локально в ICP, так и с помощью файла конфигурации yaml. В последнем случае можно описать инфраструктуру контейнеров, входящих в один Под. В следующем примере мы создадим контейнер на основе репозиторя Kubernetes, доступного всем пользователям.

Создадим Под nginx:

`kubectl create -f https://k8s.io/examples/application/shell-demo.yaml`

Получим доступ к консоли bash Пода: 

`kubectl exec -it shell-demo -- /bin/bash`

`root@shell-demo:/`

Подробнее о синтаксисе yaml можно прочесть [тут](https://www.mirantis.com/blog/introduction-to-yaml-creating-a-kubernetes-deployment/)

Набор готовых конфигурационных файлов можно найти [тут](https://github.com/IBM/charts)

# День 4 <a name="day4"></a>

## Развертывание портала и системы хранения в *IBM Cloud Private* <a name="51"></a>


В этом разделе мы развернем `СУБД PostgreSQL` на облачной платформе `IBM Cloud Private`, а также разработаем приложения для получения и хранения медицинских данных, передаваемых мобильным приложением.

![](assets/node_api.png)


**PostgreSQL** — свободная объектно-реляционная система управления базами данных (СУБД). 


### Основы работы с СУБД PostgreSQL:  установка и базовые операции <a name="511"></a>

Для получения навыков работы с `PostgreSQL` будем использовать контейнер Ubuntu, созданный в предыдущем разделе. Для этого зайдите в консоль ssh. 

Далее устанавливаем СУБД:

`sudo apt-get install postgresql`

Запускаем СУБД (если Вы используете пользователя root, то команду sudo использовать не нужно):

`sudo /etc/init.d/postgresql start`

Входим в консоль управления `PostgreSQL`:

`sudo -u postgres psql`

Обратите внимание, что при установке `PostgreSQL` создается пользователь `postgres`, не имеющий домашней директории. Поэтому запись логов и файлов блокировки процессов будет невозможна:

```
~ $ sudo -u postgres psql
[sudo] password for user: 
could not change directory to "/home/user"
psql: could not connect to server: No such file or directory
Is the server running locally and accepting
connections on Unix domain socket "/var/run/postgresql/.s.PGSQL.5432"?
```
Поэтому перед запуском команды следует перейти в `/tmp`, доступ на запись в которую для пользователя `postgres` разрешен.


Создаём базу данных:

`CREATE DATABASE my_db_1;`

Далее можно просмотреть список существующих баз данных:

`psql \l`

Подключиться к базе данных:

`psql \c my_db_1`

Создать таблицу:

`CREATE TABLE people (man TEXT, age INTEGER);`

Посмотреть список таблиц внутри базы данных:

`psql \dt`

Посмотреть тип полей определённой таблицы:

`psql \d people`

Вставка значений в таблицу:

`INSERT INTO people (man, age) VALUES ('John', 21);`

`INSERT INTO people (man, age) VALUES ('Doe', 25);`

Вывести на экран всё содержимое таблицы:

`SELECT * FROM people;`

Обновление записей в таблице:

`UPDATE people SET age = 40 WHERE man = 'John';`

Удаление записей в таблице:

`DELETE FROM people WHERE age = 40;`

Удаление таблицы из базы данных

`DROP TABLE people;`

Удаление всей базы данных:

`DROP DATABASE my_db_1;`

Более подробную информацию по работе с PostgreSQL вы можете найти [тут](https://maxim218.gitbooks.io/postgresql/content/)
 

### Развертывание СУБД PostgreSQL и Node.js сервера в одном контейнере <a name="512"></a>

Развернем новый контейнер в `ICP`, в котором установим СУБД PostgreSQL и Node.js сервер. Для этого будем использовать следующий `Docker` файл:

```
FROM ubuntu:16.04

MAINTAINER Kolotovkin Maxim

RUN apt-get -y update
ENV PGVER 9.5
RUN apt-get install -y postgresql-$PGVER

USER postgres
RUN /etc/init.d/postgresql start &&\
    psql --command "ALTER USER postgres WITH SUPERUSER PASSWORD 'XXXXXX';" &&\
    createdb -E utf8 -T template0 -O postgres my_database &&\
    /etc/init.d/postgresql stop

RUN echo "synchronous_commit = off" >> /etc/postgresql/$PGVER/main/postgresql.conf
RUN echo "fsync = off" >> /etc/postgresql/$PGVER/main/postgresql.conf

EXPOSE 5432

VOLUME  ["/etc/postgresql", "/var/log/postgresql", "/var/lib/postgresql"]

USER root
RUN apt-get -y update
RUN apt-get install -y nodejs
RUN apt-get install -y npm
RUN apt-get install -y nodejs-legacy

ENV APP /root/app
ADD ./ $APP

WORKDIR $APP

RUN npm install forever -g

RUN npm install

EXPOSE 80

RUN apt-get update && apt-get install -y openssh-server
RUN mkdir /var/run/sshd
RUN echo 'root:hackathon' | chpasswd
RUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config

RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

ENV NOTVISIBLE "in users profile"
RUN echo "export VISIBLE=now" >> /etc/profile

EXPOSE 22

WORKDIR $APP

CMD service postgresql start && forever start index.js && /usr/sbin/sshd -D
```

Замените `XXXXXX` на пароль суперпользователя postgres. 


Скачайте тестовый проект ICP_nptest. Для этого скачайте [git репозиторий](https://github.com/alexbmstu/2018.git) с помощью команды wget.

Вам понадобится архив в папке `./scr`. 

Создайте в папке с Вашим Docker файлом папку app:

`mkdir app`

Распакуйте архив ICP_nptest.zip в папку `app`. Ознакомьтесь с кодом приложения Node.js. Укажите пароль пользователя `postgres` в файле `index.js`.


Далее соберите и запускаем контейнер на сервере (см инструкции к День 3). 

Далее необходимо разрешить форвардинг портов к нашему Поду. Для
этого используем команду expose. Обратите внимание, нужно явно указывать уникальные имена сетевых сервисов:

```
$ kubectl expose deployment team00nodeapi --name=ssh00nodeapi --type=LoadBalancer --port=22 —target-port=22
service "ssh00nodeapi" exposed

$ kubectl expose deployment team00nodeapi --name=http00nodeapi --type=LoadBalancer --port=80 —target-port=80
service "http00nodeapi" exposed
```

Осталось узнать порты, которые использовал Kubernetes для форвардинга в порты 22 и 80 нашего Пода:

`$ kubectl get svc`


В результате получаем сообщение о назначении портов:

```
22/tcp -> 195.10.40.201:32776
80/tcp -> 195.10.40.201:32775
```

Подключаемся по ssh:

`ssh root@195.19.40.201 -p 32776`

Тестируем ноду в браузере по url: `http://195.19.40.201:32775/`

`HELLO NODE API`

Проверим работу node в мэнэджере `forever`:

```
root@48958c2527b2:~# forever list
info: Forever processes running
data: 	uid 	command 	script 	forever 		pid 	id 	logfile 			uptime
data:	[0] 	iiut 		/usr/bin/nodejs index.js 	48	54	/root/.forever/iiut.log 	0:0:2:37.967
```

Проверим как заполнилась БД. Для этого необходимо изменить текущего пользователя в системе:

```
root@a1eb5093b309:~/app# su - postgres
```

Входим в режим работы с psql:

```
postgres@a1eb5093b309:~$ psql
psql (9.5.14)
Type "help" for help.
```

Далее выдадим список всех БД в системе:

```
postgres=# \l
List of databases
Name         | Owner    | Encoding  | Collate | Ctype | Access privileges
-------------+----------+-----------+---------+-------+-----------------------
my_database  | postgres | UTF8      | C       | C     | 
postgres     | postgres | SQL_ASCII | C       | C     |
template0    | postgres | SQL_ASCII | C       | C     | =c/postgres +
             |          |           |         |       | postgres=CTc/postgres
template1    | postgres | SQL_ASCII | C       | C     | =c/postgres +
             |          |           |         |       | postgres=CTc/postgres
(4 rows)
```

Просмотрим список таблиц в базе my_database: 

```
postgres=# \c my_database
You are now connected to database "my_database" as user "postgres".
my_database=# \dt
List of relations
Schema  | Name   | Type  | Owner
--------+--------+-------+----------
public  | people | table | postgres
(1 row)
```

Просмотрим содержимое таблицы people

```
my_database=# select * from people;
```

Для выхода в root:

```
my_database=# \q
postgres@b639e9351a69:~$ exit
```


## Тестирование Node.js сервера <a name="52"></a>


Тест приложения пожно выполнить с помощью браузерного плагина `Postman` (подробнее об установке `Postman` можно прочитать [тут](https://www.getpostman.com/docs/v6/postman/launching_postman/installation_and_updates)).


Примеры тестовых POST и GET запросов показаны ниже:
 
![](assets/ICP_node1.png)


![](assets/ICP_node2.png)


![](assets/ICP_node3.png)


Для POST запросов на добавление используйте ссылку вида:

`http://195.19.40.201:32789/add_one_record`

Формат данных в теле запроса json следующего вида

```
{
"nickname": "Nick",
"age": 23
}
``` 

Для GET запросов на выборку используйте ссылку вида:

`http://195.19.40.201:32789/get_all_records`

Формат ответа - массив json-обьектов вида:

`[{"man_id":"1","man_nickname":"Nick","man_age":23}]`
 
Код проекта подробно описан [тут](https://maxim218.gitbooks.io/nodejs/content/chapter1.html).


Далее Вы можете проверить появление записей в таблицах базы данных `PostgreSQL` при выполнении запросов POST и их выдачу в ответ на запросы GET.


**Задание 1: Разделите Docker файл на два таким образом, чтобы:**

**- СУБД PostgreSQL работала в одном контейнере и была доступна по ssh протоколу извне.**

**- Фронтенд Node.js работал в другом контейнере и был доступен по ssh и по http.**

**- Контейнеры взаимодействовали между собой через внутреннюю виртуальную сеть Kubernetes (для этого потребуется настройка приложения Node.js на соединение с контейнером PostgreSQL).**


Для выполнения задания Вам понадобится создать локальный сетевой сервис типа `ClusterIP` для доступа к `Postgres` 

```
kubectl expose deployment team99db --name=team99-db-postgres --target-port=5432 --port=5432
```

Проверить выполнение предыдущей команды можно с помощью команды:

```
kubectl get svc, в качестве адреса для сервера берём CLUSTER-IP
```

После этого, код подключения к БД от сервера будет выглядеть следующим образом:

```
   // Описываем функцию создания нового клиента для подключения к БД
   function createNewClient() {
        return new pg.Client({
            user: 'postgres',
            host: '<CLusterIP>', // Внутренний IP ноды с Postgresql
            database: 'my_database',
            password: 'hackathon',
            port: '5432' // Порт Postgreqsl
        });
   }
```

Далее нужно настроить `postgreSQL` 

```
nano /etc/postgresql/9.5/main/postgresql.conf
```

Нужно раскоментировать строки и изменить `localhost` на `'*'`

```
          listen_addresses = 'localhost'
          password_encryption = on
```
    
Далее нужно разрешить сетевой доступ по IPv4:
 
```
nano /etc/postgresql/9.5/main/pg_hba.conf
    Здесь добавить
    # IPv4 External but internal to cluster connections
    host    all             all             10.0.0.0/8               md5
```

Теперь можно перезапустить `postgreSQL`:

```
    /etc/init.d/postgresql restart
```


**Задание 2: модифицируйте код приложения таким образом, чтобы оно принимало формат json пакетов от вашего мобильного приложения.**

*Обратите внимание, что docker контейнер PostgreSQL использует временное дисковое пространство для размежения файлов БД. Поэтому при удалении или сбое в работе контейнера данные будут потеряны. Чтобы избежать этого, необходимо предоставить контейнеру PostgreSQL доступ к долговременному хранилищу. Более подробно информацию о выделении хранилища в ICP можно найти [тут](https://www.ibm.com/support/knowledgecenter/SS4GSP_6.2.7/com.ibm.udeploy.install.doc/topics/docker_pVolumes.html)*
 

# День 5 <a name="day5"></a>

## Облачная платформа *IBM Cloud* <a name="61"></a>

***IBM Cloud*** — это открытое облачная система типа PaaS
(*Platform-as-a-Service*) на базе проекта с открытым исходным кодом Cloud Foundry. Эта платформа предназначена для разработки и хостинга приложений, а также упрощения задач по управлению инфраструктурой. Она позволяет быстро создавать и развертывать приложения, а также управлять ими.

***IBM Cloud*** обеспечивает следующие возможности:

-   быстрое и инкрементное составление приложений из сервисов;
-   непрерывное внесение изменений в приложения и обеспечение постоянной доступности;
-   поддержка высокоспециализированных моделей программирования и сервисов для конкретных рабочих нагрузок;
-   встраивание высокой степени управляемости в сервисы и приложения;
-   оптимизация и эластичная адаптация к рабочей нагрузке.


![Каталог компонентов IBM Cloud](assets/intro04.jpg)
**Каталог компонентов IBM Cloud**


Платформа *IBM Cloud* достигает этих целей посредством абстрагирования и скрытия большинства сложностей, традиционно сопутствующих хостингу приложений в облаке и управлению ими в облачной среде. *IBM Cloud* может быть использована разработчиками для создания и применения самых разных приложений, включая веб-приложения, мобильные приложения, приложения для работы с большими данными, приложения для разумных устройств и т.д. *IBM Cloud* поддерживает разработку на популярных языках программирования и средах разработки. Java-технологии, средства создания серверных частей для мобильных приложений, мониторинг приложений, технологии с открытым исходным кодом и т. д. — все эти возможности
доступны в облаке как сервисы.

Каталог *IBM Cloud* содержит большую часть из того, что необходимо для быстрого начала работы, большое количество шаблонов, заранее сконфигурированны наборов сервисов, сред исполнения и примеров кода, готовых к использованию:

-   сред исполнения, в том числе: Liberty for Java, Node.js, Ruby on Rails;
-   веб-сервисов и сервисов приложений, в том числе: Data/Session Cache,  ElasticMQ, Decision, SSO, Log Analysis, Redis, RabbitMQ, Twilio;
-   мобильных сервисов, в том числе: push-уведомлений, Cloud Code,     Mobile Application Management, Mobile Quality Assurance;
-   сервисов управления данными, в том числе: MongoDB, реляционной базы данных от IBM, JSON-базы данных от IBM, MySQL, PostgreSQL, MobileData, Mobile Sync, BLU Data Warehouse, MapReduce;
-   сервисов мониторинга и анализа;
-   сервисов DevOps Services (прежнее название: JazzHub).
-   проприетарные сервисы IBM, включая аналитическую систему SPSS и другие. 
-   когнитивные сервисы IBM Watson.


****
## Краткое описание концепций *IBM Cloud* <a name="62"></a>


В терминологии *IBM Cloud* приложение (*application*) — это созданный вами артефакт, т. е. весь программный код (исходный код или исполняемые двоичные файлы), который необходимо запустить или на который необходимо сослаться в процессе исполнения. Мобильные приложения выполняются за пределами среды *IBM Cloud* и используют сервисы *IBM Cloud*, представленные приложениями. В случае веб-приложений приложение — это код, загруженный на платформу *IBM Cloud* с целью хостинга. Кроме того, платформа *IBM Cloud* способна осуществлять хостинг программного кода приложения, который вы хотите выполнять на внутреннем сервере в среде на базе контейнера.

На рисунке показаны принципы взаимодействия *IBM Cloud* с клинтскими приложениями.


![Принципы взаимодействия *IBM Cloud* с клинтскими приложениями](assets/intro05.jpg)
**Принципы взаимодействия *IBM Cloud* с клинтскими приложениями**


***Сервис (service)*** — это код, работающий на платформе *IBM Cloud* и предлагающий некоторую функциональность, которую могут использовать приложения. Это может быть готовый сервис, используемый непосредственно — например, push-уведомления для мобильных приложений или эластичное кэширование для веб-приложения. Вы также можете создавать собственные сервисы в диапазоне от простых служебных функций до сложной
бизнес-логики.

***Организация (organization) и пространство (space)*** — это организационные единицы инфраструктуры, способные хранить и отслеживать ресурсы приложения. Организация содержит домены (domain), пространства и пользователей. Пространство содержит приложения и сервисы. По умолчанию используется три пространства: Development (разработка), Production (производство) и Staging (подготовка). Для приложений, которым требуется среда типа PaaS, предоставляются buildpack-пакеты, каждый из которых представляет собой набор скриптов для подготовки кода к исполнению на целевой PaaS-платформе. Buildpack-пакеты, которые включают необходимую вашим приложениям среду исполнения и могут также содержать специализированные инфраструктуры, упрощают развертывание приложения в облаке по сравнению с самостоятельной установкой и конфигурированием среды исполнения.

Использование сервисов в *IBM Cloud* включает три этапа:
1.  Сообщите платформе *IBM Cloud*, что вам требуется новый экземпляр сервиса и какое конкретное приложение будет использовать этот новый экземпляр.
2.  *IBM Cloud* автоматически инициализирует новый экземпляр этого сервиса и свяжет его с приложением.
3.  Приложение взаимодействует с сервисом.

***Пакеты сервисов (Service bundles)*** — это коллекции API-интерфейсов, используемых в конкретных областях. Например, пакет Mobile Services включает сервисы MobileData, Cloud Code, Push и Mobile Application Management. Доступные сервисы и среды исполнения представлены в каталоге IBM Cloud. Кроме того, вы можете зарегистрировать собственные сервисы.

****
## Развертывание и управление приложением <a name="63"></a>

Чтобы развернуть свое приложение, необходимо загрузить его в среду *IBM Cloud* и указать, сколько экземпляров этого приложения должно исполняться, а затем сконфигурировать *IBM Cloud*, введя необходимую информацию для поддержки этого приложения.

В случае мобильного приложения среда *IBM Cloud* содержит артефакт, который представляет серверную часть мобильного приложения — набор сервисов, который использует приложение для взаимодействия с сервером. *IBM Cloud* поддерживает серверные компоненты мобильного приложения, взаимодействующие с сервисами PushWorks, Cloud Code и Mobile Data, непосредственно из пользовательского интерфейса *IBM Cloud*.

В случае веб-приложения необходимо предоставить в *IBM Cloud* соответствующую информацию о среде исполнения и среде разработки, чтобы платформа смогла сформировать надлежащую инфраструктуру для исполнения этого приложения.

При развертывании приложений и управлении ими можно использовать инструмент командной строки cf, веб-интерфейс *IBM Cloud* или сервисы DevOps Services.

Браузерные и мобильные клиенты — а также другие приложения, развернутые на платформе *IBM Cloud* и выполняющиеся за ее пределами — взаимодействуют с приложениями, работающими на платформе *IBM Cloud*, через API-интерфейсы типа REST/HTTP. Каждый клиентский запрос маршрутизируется к одному из экземпляров приложения или составляющих его сервисов. Среды исполнения приложений в *IBM Cloud* изолированы друг от друга даже тогда, когда они находятся на одной и той же физической машине.

В ходе управления приложениями можно запускать, останавливать, перезапускать экземпляры приложения (или, в случае веб-приложения, изменять их количество), а также изменять объем памяти, используемый приложением. Ключевая конструктивная особенность *IBM Cloud* — отличные показатели при хостинге масштабируемых приложений и артефактов приложений. На данный момент эта платформа не масштабирует приложение автоматически в соответствии с нагрузкой, поэтому этим процессом необходимо управлять самостоятельно посредством создания или удаления экземпляров при изменении рабочей нагрузки. По этой причине ваши приложения должны сохранять все персистентные данные за пределами приложения в одном из сервисов хранения данных, предоставляемых платформой *IBM Cloud*. При повторном развертывании приложения после обновления используется тот же процесс, что и при начальном развертывании. *IBM Cloud* останавливает все исполняющиеся экземпляры и переводит новые экземпляры в рабочее состояние автоматически.

****
## Сервисы DevOps Services для *IBM Cloud* <a name="64"></a>

При использовании DevOps Services требуется лишь несколько простых шагов для организации взаимодействия с другими специалистами с целью планирования, отслеживания и создания программного обеспечения в облаке. Вы можете воспользоваться встроенным в браузер редактором программного кода, который DevOps Services предоставляет для разработки приложений, или использовать DevOps Services с Eclipse, с VisualStudio или с инструментом командной строки Git для написания кода приложения и развертывания его на платформе IBM Cloud.

При работе с пользовательским интерфейсом, который помогает разработчику быстро добавлять сведения "кто", "что" и "когда" для своего рабочего проекта, требуется потратить всего несколько минут на задание дат, документирование первого сценария применения, назначение одной-двух задач и переход непосредственно к написанию программного кода.

DevOps Services включает встроенные средства управления исходным кодом — Jazz SCM и хостинговый Git. Каждый проект получает свой собственный репозиторий DevOps Services и рабочее пространство, в котором участники этого проекта могут регистрироваться свои изменения, ассоциировать изменения программного кода и просматривать историю недавних изменений. Кроме того, вы можете создать проект DevOps Services и указать на свой репозиторий GitHub.

Вы также можете с легкостью связать элементы работы с изменениями кода в GitHub. Кроме того, для написания кода в Git вы можете использовать имеющиеся у вас инструменты.

Типичными сценариями использования ресурса DevOps Services являются:

-   Создание приложения для анализа данных социальных сетей с использованием Node.js, Node-RED, Express, sentiment и ntwitter.
-   Создание приложения для создания интерактивных опросов в реальном     времени с использованием Node.js, Node-RED, Express, AngularJS и MongoDB.
-   Построение сервисов уведомления с использованием Node.js, Node-RED и MongoDB.
-   Создание приложений для управления аппаратными устройствами c использованием Node-RED и IoT компонент.


****
## Блокчейн технологии <a name="65"></a>


Смарт-контракт – это запрограммированная бизнес-логика и правила взаимодействия с данными, которые размещены в распределенном реестре (ledger). Реестр содержит цепочку блоков транзакций, которые совершили участники сети. Каждый последующий блок хранит хэш предыдущего блока, за счет чего обеспечивается невозможность изменения части информации. Процесс согласования корректности блока и добавления его в распределенный реестр называется консенсусом. Различные блокчейн-платформы имеют различные механизмы консенсуса: proof of work (PoW), proof of stake (PoS), byzantine fault tolerance (BFT) и прочие.

## Решение Hyperledger Fabric <a name="66"></a>

`Hyperledger` — это консорциум в рамках проекта `Linux Foundation`. `Hyperledger Fabric (HLF)` — реализация технологии блокчейн с контролируемым доступом (permissioned) для построения широкого спектра решений. Участники, взаимодействующие через `Hyperledger Fabric` определяются на этапе проектирования сети и могут иметь различные роли. Наиболее понятными сценариями для таких сетей являются цепочки поставок, в которых участвует множество независимых компаний. С технической точки зрения каждый участник имеет развернутый участок сети у себя в организации (или в облачной инфраструктуре), но не имеет доступа к участкам сети, развернутым в других компаниях. Начиная с версии 1.0 HLF специфична наличием Ordering Service, который является распределенным между участниками кластером и отвечает за очередность транзакций в формирующемся блоке. По сконфигурированным параметрам он собирает транзакции в сети и формирует блок. В случае отказа Ordering Service транзакции в сети перестанут регистрироваться, но сами данные останутся неизменными.

****
## Развертывание сети Blockchain с использованием API-интерфейсов Kubernetes на IBM Cloud <a name="66"></a>


Сеть Hyperledger Fabric можно развернуть несколькими способами:

* [Самостоятельно развернуть сеть нодов HLF из Docker образов](http://hyperledger-fabric.readthedocs.io/en/release-1.0/build_network.html)

* Использовать [Blockchain как услугу](https://console.bluemix.net/catalog/services/blockchain), размещенную в [IBM Cloud](https://console.bluemix.net/). `IBM Cloud` предоставляет доступ к HLF Blockchain как услугу для пользователей Starter и Enterprise Membership Plan (студенческий и преподавательский доступ МГТУ).

* Использовать сеть Hyperledger Fabric под управлением [Kubernetes](https://console.bluemix.net/containers-kubernetes/catalog/cluster), разворачиваемый через [службу IBM Cloud Container](https://console.bluemix.net/containers-kubernetes/catalog/cluster)

В этом примере мы будем использовать третий вариант: развернем и настроим сеть нодов  `Hyperledger Fabric` с использованием Kubernetes кластера в IBM Cloud Container Service.

Хостинг сети `Hyperledger Fabric` в `IBM Cloud` предоставляет много преимуществ:

- хостинг тестового решения будет выполнен на стороннем ресурсе;
- с одной системой смогу работать одновременно несколько пользователей
- решение может быть клонировано, сохранено на локальные машины и повторно развернуто на более продуктивной системе, в том числе на `IBM CLoud Private`. Обратите внимание, что настройка сети blockchain на Kubernetes удобна для демонстрационных сценариев, но для производства рекомендуется использовать `Blockchain` как услугу, размещенную на `IBM Cloud`.

****
## Использование Kubernetes в IBM Cloud <a name="67"></a>

[IBM Cloud Container](https://console.bluemix.net/containers-kubernetes/catalog/cluster) позволяет создать бесплатный кластер с двумя процессорами, 4 ГБ оперативной памяти и одним рабочим узлом. Это позволяет вам познакомиться и проверить возможности `Kubernetes`. Для реализации продуктивной работы такому решению не хватает некоторых возможностей, таких как использование файлового хранилища NFS и др..

Чтобы настроить кластер для максимальной доступности и емкости, IBM Cloud позволяет создать полностью настраиваемый, готовый к тестированию кластер под названием `_standard cluster_`. `_Standard cluster_` позволяют использовать различные конфигурации. Например, имеется возможность объединить два кластера, которые работают в разных регионах IBM Cloud, каждый из которых содержит несколько рабочих узлов. См. [https://console.bluemix.net/docs/containers/cs_planning.html#cs_planning_cluster_config](https://console.bluemix.net/docs/containers/cs_planning.html#cs_planning_cluster_config), чтобы познакомиться с другими вариантами построения высокодоступных конфигураций кластера.

Далее мы будем рассматривать шаблон `_free cluster_`, предоставляемый `IBM Cloud`. Этот шаблон предоставляет вам сценарии для автоматизации процесса настройки сети `Hyperledger Fabric` с использованием API-интерфейса `Kubernetes` в `IBM Cloud`.

****
## Развертывание blockchain решения <a name="68"></a>

  ![](assets/architecture.png)

После регистрации в IBM Cloud вы получите доступ в графический интерфейс управления вашей инфраструктурой. Далее необходимо в левом верхнем углу нажать на кнопку меню и выбрать `Containers`. Нам понадобится развернуть новый `Kubernetes Service`. Выбрав слева в меню пункт `Cluster`, вы увидите интерфейс создания кластера kubernetes и выбор региона, в котором кластер будет развернут. Вы можете создать бесплатный кластер в каждом регионе.

После нажатия кнопки `Create` следует выбрать тип кластера `Free` (_free cluster_) и придумать ему название. Создание кластера займет некоторое время.

Войдите в `IBM Cloud CLI` и выполните инициализацию плагина `IBM Cloud Container Service`.

Для этого установите плагин для bx для работы с kubernetes в IBM Cloud:

`bx plugin install container-service -r Bluemix`

Авторизуйтесь в IBM Cloud:

`bx login -a https://api.eu-gb.bluemix.net`

Укажите регион, где вы создали Ваш кластер (обычно, UK-south):

`bx cs region-set uk-south`

Запросить конфигурацию для вашего кластера, где mycluster — название, которые Вы ввели в графическом интерфейсе IBM Cloud;

`bx cs cluster-config mycluster`

Далее выполните команду, которую вы увидите в результате выполнения предыдущего шага. Она укажет утилите `kubectl`, где находятся ключи доступа к вашему кластеру (путь к конфигурационному файлу может меняться):

`export KUBECONFIG=/path/mycluster/kube-config-mil01-mycluster.yml`

Вы также должны узнать public IP вашего kubernetes worker узла:

`bx cs workers mycluster`

Проверьте, что `kubectl` настроен на `IBM CLoud`:

```
kubectl version  --short
Client Version: v1.9.2
Server Version: v1.8.6-4+9c2a4c1ed1ee7e

kubectl get pods
NAME                          READY     STATUS    RESTARTS   AGE
mycluster-54958d8d9-t5gc2     1/1       Running   0          40d

```

Теперь вы готовы к тому, чтобы начать использовать ваш `kubernetes`-кластер для любых целей. Кластер является бесплатным, в его функционале есть некоторые ограничения, которые нам не помешают развернуть свою блокчейн-сеть

 
## Развертывание сети Hyperledger в Kubernetes <a name="611"></a>

Этот шаблон предоставляет сценарий, который автоматически создает сеть Hyperledger Fabric, состоящую из четырех организаций, каждая из которых поддерживает один одноранговый узел. Кроме того, скрипт создает канал с именем «channel1», соединяет все узлы с каналом «channel1», устанавливает цепочку кодов на всех одноранговых узлах и создает цепочку цепочек на канале. Шаблон также помогает управлять выполнением транзакций по развернутому цепочному коду.

Клонируйте сценарии конфигурации Kubernetes в домашний каталог вашего компьютера:

`git clone https://github.com/IBM/blockchain-network-on-kubernetes.git`

Перейдите в каталог c исходными кодами проекта:

  ```
  cd blockchain-network-on-kubernetes
  ls
  ```

В каталоге находятся файлы:

* `configFiles`  - файлы конфигурации Kubernetes

* `artifacts` - файлы конфигурации сети

* `*.sh` - скрипты для развертывания и удаления сети
  
Если есть какие-либо изменения в топологии сети, необходимо соответствующим образом изменить файлы конфигурации (.yaml-файлы). Файлы конфигурации находятся в каталоге `artifacts` и` configFiles`. Например, если вы решите увеличить / уменьшить емкость хранилища, вам необходимо изменить параметры хранилища в файле`createVolume.yaml`.

## Запуск сценария для развертывания сети узлов <a name="613"></a>

После того, как вы получили файлы конфигурации, вы можете развернуть свою сеть. Выполните сценарий для развертывания blockchain сети.

  ```
  $ chmod + x setup_blockchainNetwork.sh
  $ ./setup_blockchainNetwork.sh
  ```

## Удалить сеть <a name="614"></a>

Если необходимо, вы можете удалить сеть с помощью скрипта `deleteNetwork.sh`. Этот скрипт удалит все ваши контейнеры, задания, deployments и т.д. из вашего кластера `Kubernetes`.

  ```
  $ chmod + x deleteNetwork.sh
  $ ./deleteNetwork.sh
  ```

## Протестируйте развернутую сеть <a name="615"></a>

После успешного выполнения скрипта `setup_blockchainNetwork.sh`, проверьте состояние контейнеров.

```
kubectl get pods
NAME                                    READY     STATUS    RESTARTS   AGE
blockchain-ca-7848c48d64-2cxr5          1/1       Running   0          4m
blockchain-orderer-596ccc458f-thdgn     1/1       Running   0          4m
blockchain-org1peer1-747d6bdff4-4kzts   1/1       Running   0          4m
blockchain-org2peer1-7794d9b8c5-sn2qf   1/1       Running   0          4m
blockchain-org3peer1-59b6d99c45-dhtbp   1/1       Running   0          4m
blockchain-org4peer1-6b6c99c45-wz9wm    1/1       Running   0          4m
```

Как упоминалось выше, скрипт объединяет все одноранговые узлы на один канал `channel1` и инициализирует цепочку blockchain на всех одноранговых узлах. Это означает, что мы можем выполнить команду invoke / query на любом равноправном узле, и ответ должен быть одинаковым для всех одноранговых узлов. Обратите внимание, что в этом шаблоне отключена служба сертификации, чтобы сократить время развертывания и сложность инструкции. Более детальная информация о развертывании Hyperledger Fabric может быть найдена [тут](https://hyperledger-fabric.readthedocs.io) 

Для запуска процесса выполнения blockchain запроса с любым партнером необходимо войти в оболочку bash однорангового узла, запустить запрос и выйти из однорангового узла. Используйте следующую команду, чтобы попасть в оболочку bash однорангового узла:

  ```
  $ kubectl exec -it <blockchain-org1peer1 pod name> bash
  ```

Для выходы вы можете использовать команду:

  ```
  # exit
  ```

В исходном проекте был создан Chaincode со значениями `{a: 100, b: 200}`.  Выдадим запрос у узла `org1peer1` о текущем зачении ключа `a`, чтобы убедиться, что цепочный код был правильно создан.


```sh
root@blockchain-org1peer1-7d95cbfd64-ttmq2:/# peer chaincode query -C channel1 -n cc -c '{"Args":["query","a"]}'
2018-11-22 18:37:56.156 UTC [msp] GetLocalMSP -> DEBU 001 Returning existing local MSP
2018-11-22 18:37:56.156 UTC [msp] GetDefaultSigningIdentity -> DEBU 002 Obtaining default signing identity
2018-11-22 18:37:56.156 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 003 Using default escc
2018-11-22 18:37:56.156 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 004 Using default vscc
2018-11-22 18:37:56.156 UTC [chaincodeCmd] getChaincodeSpec -> DEBU 005 java chaincode disabled
2018-11-22 18:37:56.157 UTC [msp/identity] Sign -> DEBU 006 Sign: plaintext: 0AA3070A6308031A0B0884EFDBDF0510...120263631A0A0A0571756572790A0161 
2018-11-22 18:37:56.157 UTC [msp/identity] Sign -> DEBU 007 Sign: digest: 6B6CE906AE6133412FAD14FBC53533DD26B82EF44605243464334AD98B5F8C32 
Query Result: 100
2018-11-22 18:37:56.178 UTC [main] main -> INFO 008 Exiting.....

```


Теперь отправим запрос к `org1peer1`, чтобы переместить 20 единиц из ` a` в `b`. Будет создана новая транзакция, и после успешного завершения транзакции состояние будет обновлено.


```sh
root@blockchain-org1peer1-7d95cbfd64-ttmq2:/# peer chaincode invoke -o blockchain-orderer:31010 -C channel1 -n cc -c '{"Args":["invoke","a","b","20"]}'
2018-11-22 18:41:36.711 UTC [msp] GetLocalMSP -> DEBU 001 Returning existing local MSP
2018-11-22 18:41:36.711 UTC [msp] GetDefaultSigningIdentity -> DEBU 002 Obtaining default signing identity
2018-11-22 18:41:36.713 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 003 Using default escc
2018-11-22 18:41:36.713 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 004 Using default vscc
2018-11-22 18:41:36.714 UTC [chaincodeCmd] getChaincodeSpec -> DEBU 005 java chaincode disabled
2018-11-22 18:41:36.715 UTC [msp/identity] Sign -> DEBU 006 Sign: plaintext: 0AA4070A6408031A0C08E0F0DBDF0510...696E766F6B650A01610A01620A023230 
2018-11-22 18:41:36.715 UTC [msp/identity] Sign -> DEBU 007 Sign: digest: 4BCF82ACFD37554A86B19A3C1147BA3E473EF8CD6B1D2A1D5A1335DA4D51DD4D 
2018-11-22 18:41:36.735 UTC [msp/identity] Sign -> DEBU 008 Sign: plaintext: 0AA4070A6408031A0C08E0F0DBDF0510...DABE53824161E5265121E39183CCABED 
2018-11-22 18:41:36.735 UTC [msp/identity] Sign -> DEBU 009 Sign: digest: BFE329AFC2830609FAC722E0AC9230E73495B3360C85F830427F1BB7FC12483C 
2018-11-22 18:41:36.741 UTC [chaincodeCmd] chaincodeInvokeOrQuery -> DEBU 00a ESCC invoke result: version:1 response:<status:200 message:"OK" > payload:"\n c*\203\322\"k\351\336\240\215\260\353\347\n\252\t\3319'v\240\365\355\313J\362f>\3540f\300\022S\nA\022+\n\002cc\022%\n\007\n\001a\022\002\010\001\n\007\n\001b\022\002\010\001\032\007\n\001a\032\00280\032\010\n\001b\032\003220\022\022\n\004lscc\022\n\n\010\n\002cc\022\002\010\001\032\003\010\310\001\"\t\022\002cc\032\0031.0" endorsement:<endorser:"\n\007Org1MSP\022\222\006-----BEGIN CERTIFICATE-----\nMIICGDCCAb+gAwIBAgIQKtNDOa1IlNQX9GocXWPpTjAKBggqhkjOPQQDAjBzMQsw\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\nYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UEAxMTY2Eu\nb3JnMS5leGFtcGxlLmNvbTAeFw0xODExMjIxODI3MTdaFw0yODExMTkxODI3MTda\nMFsxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1T\nYW4gRnJhbmNpc2NvMR8wHQYDVQQDExZwZWVyMC5vcmcxLmV4YW1wbGUuY29tMFkw\nEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE34RrdhgwrExCzne7t2Q/gPgQ21m+c5G+\naCCuBGfDceVS+mol+PC39FePtMP3c0iDVDhwPI9UGTTeM316C0lpg6NNMEswDgYD\nVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAggca8Yy4TN3A+\nGWL+fxflCScOOh5+PfHHqjY0wWuDanYwCgYIKoZIzj0EAwIDRwAwRAIgUN6Z8R5b\nrELp0gFyzeSoxWW1StUttju8v4m+XOLxCI4CIB5/b8cm+gU5ouvPs1iza6H7F35D\nHO9ZpVREzqu7H/lz\n-----END CERTIFICATE-----\n" signature:"0D\002 D\003\t:\013DX\243Pu<f4\244<\363\034\035\333{\224'\350\376\327\350W\351L\343\017\257\002 rv\024H\312\250\t\236F\363\365%PS\231\355\332\276S\202Aa\345&Q!\343\221\203\314\253\355" > 
2018-11-22 18:41:36.741 UTC [chaincodeCmd] chaincodeInvokeOrQuery -> INFO 00b Chaincode invoke successful. result: status:200 
2018-11-22 18:41:36.742 UTC [main] main -> INFO 00c Exiting.....
```

Давайте подтвердим, что наш предыдущий вызов выполнен правильно. Мы инициализировали ключ `a` со значением 100 и просто удалили 20 с помощью нашего предыдущего вызова. Поэтому ключ `a` должен показывать 80, ключ ` b` должен показывать 220. 

```sh
root@blockchain-org1peer1-7d95cbfd64-ttmq2:/# peer chaincode query -C channel1 -n cc -c '{"Args":["query","a"]}'
2018-11-22 18:41:52.035 UTC [msp] GetLocalMSP -> DEBU 001 Returning existing local MSP
2018-11-22 18:41:52.035 UTC [msp] GetDefaultSigningIdentity -> DEBU 002 Obtaining default signing identity
2018-11-22 18:41:52.035 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 003 Using default escc
2018-11-22 18:41:52.035 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 004 Using default vscc
2018-11-22 18:41:52.035 UTC [chaincodeCmd] getChaincodeSpec -> DEBU 005 java chaincode disabled
2018-11-22 18:41:52.036 UTC [msp/identity] Sign -> DEBU 006 Sign: plaintext: 0AA3070A6308031A0B08F0F0DBDF0510...120263631A0A0A0571756572790A0161 
2018-11-22 18:41:52.036 UTC [msp/identity] Sign -> DEBU 007 Sign: digest: B7968F08A80E4F09FCB7E714A5741386C9206AB896103A0E883F2B6030B38EA2 
Query Result: 80
2018-11-22 18:41:52.053 UTC [main] main -> INFO 008 Exiting.....
```

и

```sh
root@blockchain-org1peer1-7d95cbfd64-ttmq2:/# peer chaincode query -C channel1 -n cc -c '{"Args":["query","b"]}'
2018-11-22 18:45:11.948 UTC [msp] GetLocalMSP -> DEBU 001 Returning existing local MSP
2018-11-22 18:45:11.948 UTC [msp] GetDefaultSigningIdentity -> DEBU 002 Obtaining default signing identity
2018-11-22 18:45:11.949 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 003 Using default escc
2018-11-22 18:45:11.949 UTC [chaincodeCmd] checkChaincodeCmdParams -> INFO 004 Using default vscc
2018-11-22 18:45:11.950 UTC [chaincodeCmd] getChaincodeSpec -> DEBU 005 java chaincode disabled
2018-11-22 18:45:11.951 UTC [msp/identity] Sign -> DEBU 006 Sign: plaintext: 0AA4070A6408031A0C08B7F2DBDF0510...120263631A0A0A0571756572790A0162 
2018-11-22 18:45:11.951 UTC [msp/identity] Sign -> DEBU 007 Sign: digest: AA2A7E3E751EA702819BA4386FF82E602783B359BE9F152EA799FDC9634026D5 
Query Result: 220
2018-11-22 18:45:11.963 UTC [main] main -> INFO 008 Exiting.....

```

Теперь выпустите запроса на `org2peer1`, `org3peer1` и` org4peer1` и проверьте идентичность ключей.


## Просмотр панели Kubernetes <a name="616"></a>

Получите токен, используя следующую команду для проверки подлинности панели инструментов Kubernetes.

  ```
  $ kubectl config view -o jsonpath = '{.users[0].user.auth-provider.config.id-token}'
  ```

Скопируйте токен. Запустите панель управления Kubernetes с портом 8001 по умолчанию.

  ```
  $ kubectl proxy
  ```

Откройте URL-адрес http://localhost:8001/ui в веб-браузере  на вашем компьютере, чтобы увидеть панель инструментов `Kubernetes`. Пройдите аутентификацию.

  ![](assets/provide-token-for-dashboard.png)

Предоставьте токен и `SIGN-IN`. На вкладке «Нагрузки» вы можете увидеть ресурсы, созданные с помощью скриптов.

  ![](assets/kubernetes-dashboard.png)

Тепеь blockchain сеть готова к использованию. Вы можете приступить к разработке своих программных блоков с помощью `sdk` или `url` развернутой сети.

## Подключение к сети с помощью клиентского SDK <a name="617"></a>

Для разработки вашего `blockchain`-приложения в развернутой сети вам необходимо подключиться к этой сети с помощью клиентского SDK. Для подключения к сети:

* Получите публичный IP-адрес своего кластера кубернетов из IBM Cloud Dashboard.

* Подключите этот публичный IP-адрес и порты, открытые с помощью [services](https://github.com/IBM/blockchain-network-on-kubernetes/blob/master/configFiles/blockchain-services.yaml).

Например: Порт узла равен «30054», поэтому URL-адрес клиент будет `http://<общедоступный IP-адрес вашего кластера>:30054/`

Таким образом, клиент может быть создан как:

  ```
  fabric_ca_client = new Fabric_CA_Client ('http://<общедоступный IP-адрес вашего кластера>:30054/', tlsOptions, 'CA1', crypto_suite);
  ```

Аналогичным образом, следующий код может использоваться для настройки сети.

  ```
  // setup the fabric network
  var fabric_client = new Fabric_Client();
  
  var channel = fabric_client.newChannel('channel1');
  var peer = fabric_client.newPeer('grpc://< public IP of your cluster >:30110');
  channel.addPeer(peer);
  var order = fabric_client.newOrderer('grpc://< public IP of your cluster >:31010')
  channel.addOrderer(order);
  ```


## Полезные ссылки к дню 5 <a name="618"></a>

* [Примеры и учебные материалы по Hyperledger Fabric](https://github.com/CATechnologies/blockchain-tutorials)

* [Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-1.1/)

* [Развертывание Fabric](https://github.com/IBM/blockchain-network-on-kubernetes/blob/master/README.md)

* [Пример Fabric nodejs](https://github.com/hyperledger/fabric-samples/blob/release/fabcar/query.js)

* [Kubernetes](https://kubernetes.io/docs/concepts/)

* [Управление кластером Kubernetes в IBM Cloud](https://console.bluemix.net/docs/containers/cs_clusters.html#planning_clusters)


# День 6 <a name="day6"></a>

## Разработка приложения для доступа к кластеру *Hyperledger Fabric* <a name="71"></a>

Разработаем приложение, которое образается к развернутому нами кластеру `Hyperledger Fabric`. Для этого узнаем `ip` адрес и порты управляющего пода канала (`blockchain-ca`), секвенсера запросов (`blockchain-orderer`) и одного из пиров (`blockchain-org1peer1`). 

```
$ kubectl get svc
NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                           AGE
blockchain-ca          NodePort       172.21.74.249    <none>        30054:30054/TCP                   3d
blockchain-orderer     NodePort       172.21.235.98    <none>        31010:31010/TCP                   3d
blockchain-org1peer1   NodePort       172.21.30.78     <none>        30110:30110/TCP,30111:30111/TCP   3d
blockchain-org2peer1   NodePort       172.21.204.175   <none>        30210:30210/TCP,30211:30211/TCP   3d
blockchain-org3peer1   NodePort       172.21.243.238   <none>        30310:30310/TCP,30311:30311/TCP   3d
blockchain-org4peer1   NodePort       172.21.184.139   <none>        30410:30410/TCP,30411:30411/TCP   3d
kubernetes             ClusterIP      172.21.0.1       <none>        443/TCP                           43d
mycluster03            LoadBalancer   172.21.155.180   <pending>     2022:32022/TCP                    43d
```

Данные адреса понадобятся в приложении, которое будет обращаться к кластеру и выполнять тразакции.
Пример приложение вы можете скачать [тут](https://github.com/maxim218/medicsBlockChain/)

Далее необходимо установить Node.js приложение на Вашем сервере ICP (см. день 4). 


Внутри папки **chaincode/fabcar/node** ставим библиотеки NodeJS

```
npm install
```

Внутри папки **fabcar** ставим библиотеки NodeJS

```
npm install
```

Заходим в папку **fabcar**

```
cd fabcar
```

Запускаем fabric

```
sudo bash ./startFabric.sh node
```

Добавляем админа

```
node enrollAdmin.js
```

Добавляем пользователя

```
node registerUser.js
```

Запускаем сервер

```
npm start
```

При этом нужно настроить ряд параметров для коммуникации: 


![Изменения в настройках приложения](assets/hyperledger_example.png)

Далее вы можете использовать `Python` скрипт. Скрипт может быть запущен как на сервере ICP, так и на машине пользователя. В последнем случае необходимо поменять ip адрес с `Localhost` на адрес сервера.


```
python ./send.py
```




#IP адреса <a name="99"></a>

Starting Nmap 7.60 ( https://nmap.org ) at 2018-10-26 14:58 MSK
Nmap scan report for _gateway (192.168.10.1)
Host is up (0.00035s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: 5C:D9:98:49:DE:45 (D-Link)

Nmap scan report for 192.168.10.70
Host is up (0.0010s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: E8:04:62:6E:B3:40 (Cisco Systems)

Nmap scan report for 192.168.10.71
Host is up (0.0010s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: EC:44:76:BE:0C:C0 (Cisco Systems)

Nmap scan report for 192.168.10.83
Host is up (0.00067s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: B8:27:EB:40:03:5F (Raspberry Pi Foundation)

Nmap scan report for 192.168.10.85
Host is up (0.00063s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: B8:27:EB:1C:00:9B (Raspberry Pi Foundation)

Nmap scan report for 192.168.10.86
Host is up (0.00079s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: E8:04:62:6E:B4:C0 (Cisco Systems)

Nmap scan report for 192.168.10.88
Host is up (-0.100s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: B8:27:EB:A4:02:5F (Raspberry Pi Foundation)

Nmap scan report for 192.168.10.89
Host is up (-0.100s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: 02:81:F1:72:D7:9D (Unknown)

Nmap scan report for 192.168.10.90
Host is up (-0.099s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: 00:E0:4C:68:07:4C (Realtek Semiconductor)

Nmap scan report for 192.168.10.93
Host is up (-0.100s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: F8:CA:B8:16:D1:14 (Dell)

Nmap scan report for 192.168.10.94
Host is up (-0.100s latency).

PORT   STATE         SERVICE
22/tcp open|filtered ssh
MAC Address: B8:27:EB:4B:CA:35 (Raspberry Pi Foundation)

Nmap scan report for alexpopov-ThinkPad-S1-Yoga (192.168.10.59)
Host is up.

PORT   STATE         SERVICE
22/tcp open|filtered ssh

Nmap done: 256 IP addresses (18 hosts up) scanned in 4.70 seconds
****
# Дополнительные источники <a name="a001"></a>

<a name="pub1">[1]</a> [Учебные материалы по IBM Cloud Private](https://github.com/phthom/IBMCloudPrivate)

<a name="pub1">[2]</a> [Инструкции по развертыванию IBM Cloud Private на виртуальной машине десктопа](https://github.com/IBM/deploy-ibm-cloud-private)

<a name="pub1">[3]</a> [Инструкции по развертыванию IBM Cloud Private на сервере](https://www.ibm.com/support/knowledgecenter/en/SSBS6K_2.1.0.2/installing/install_containers_CE.html)

<a name="pub1">[4]</a> [Docker образы IBM Cloud Private CE 2.1](https://hub.docker.com/r/ibmcom/icp-inception/)



